<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>DTL_KG</title><style type="text/css"> * {margin:0; padding:0; text-indent:0; }
 .s1 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; }
 .s2 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11pt; }
 .s4 { color: black; font-family:Georgia-BoldItalic, serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 9pt; }
 .h3 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 .p, p { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; margin:0pt; }
 .s5 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 h1 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 29.5pt; }
 .s6 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s7 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s8 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s9 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s10 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 5pt; }
 .s11 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s12 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: -1pt; }
 .s13 { color: black; font-family:"Arial Unicode MS", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 10pt; }
 .s14 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 2pt; }
 .s15 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s16 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: -1pt; }
 .s17 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s18 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -2pt; }
 .s19 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s20 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s21 { color: black; font-family:"Arial Unicode MS", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 5pt; }
 .s22 { color: black; font-family:Menlo, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s23 { color: black; font-family:Menlo, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 3pt; }
 .s24 { color: black; font-family:Menlo, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s25 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 3pt; }
 .s26 { color: black; font-family:"Arial Unicode MS", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s27 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: 3pt; }
 .s28 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: underline; font-size: 7pt; vertical-align: 4pt; }
 .s29 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: underline; font-size: 5pt; vertical-align: 3pt; }
 .s30 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 3pt; }
 .s31 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: 3pt; }
 .h2, h2 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 .s32 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; vertical-align: 2pt; }
 .s33 { color: black; font-family:"Arial Unicode MS", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; }
 .s34 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 6.5pt; }
 .s37 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s38 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 6pt; vertical-align: -1pt; }
 .s39 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s40 { color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 4pt; vertical-align: -2pt; }
 .s41 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 7.5pt; vertical-align: -2pt; }
 .s42 { color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5.5pt; vertical-align: -3pt; }
 .s43 { color: #FC0005; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 9pt; }
 .s44 { color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -1pt; }
 .s45 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 7.5pt; }
 .s46 { color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -1pt; }
 .s47 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 8pt; vertical-align: -2pt; }
 .s48 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; vertical-align: -1pt; }
 .s49 { color: black; font-family:"Helvetica Neue", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s50 { color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7.5pt; vertical-align: 1pt; }
 .s51 { color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s52 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 6pt; vertical-align: 1pt; }
 .s53 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 2pt; }
 .s54 { color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 4pt; }
 .s55 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 1pt; }
 .s56 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s57 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7.5pt; }
 .s58 { color: black; font-family:"Helvetica Neue", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; }
 .s59 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; }
 .s60 { color: black; font-family:Arial-BoldItalicMT, sans-serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 10pt; }
 .s61 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 1pt; }
 .s62 { color: black; font-family:Menlo, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 1pt; }
 .s63 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s64 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s65 { color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 7pt; }
 .s66 { color: black; font-family:"Arial Unicode MS", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 7pt; }
 .s67 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 3pt; }
 .s68 { color: black; font-family:Arial-BoldItalicMT, sans-serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 7pt; }
 .s69 { color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s70 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -2pt; }
 .s71 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -3pt; }
 .s72 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 4.5pt; vertical-align: -1pt; }
 .s73 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -3pt; }
 .s74 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -4pt; }
 .s75 { color: black; font-family:Georgia-BoldItalic, serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 10pt; }
 .s76 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 6.5pt; vertical-align: -1pt; }
 .s77 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 1pt; }
 .s78 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; }
 .s79 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: -3pt; }
 .s80 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s81 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5.5pt; }
 .s82 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 4pt; }
 .s83 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -2pt; }
 .s84 { color: #262626; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 3pt; vertical-align: -1pt; }
 .s85 { color: #262626; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 2.5pt; }
 .s86 { color: #262626; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 3pt; }
 .s87 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; }
 .s88 { color: #231F20; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; }
 .s89 { color: #231F20; font-family:"Microsoft Sans Serif", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s90 { color: #262626; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 3pt; vertical-align: 1pt; }
 .s91 { color: #262626; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 2.5pt; vertical-align: 1pt; }
 .s92 { color: #231F20; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s93 { color: #231F20; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 2.5pt; }
 .s94 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -3pt; }
 .s95 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s96 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; vertical-align: 4pt; }
 .s97 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 4pt; }
 .s98 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 10pt; vertical-align: -5pt; }
 .s99 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -5pt; }
 .s100 { color: black; font-family:"Arial Unicode MS", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -2pt; }
 .s101 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 1pt; }
 .s102 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s103 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 4pt; }
 .s104 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 3pt; }
 .s105 { color: black; font-family:Menlo, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 4pt; }
 .s106 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 10pt; }
 .s107 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 1pt; }
 .s108 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 1pt; }
 .s109 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -2pt; }
 .s110 { color: black; font-family:Arial-BoldItalicMT, sans-serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 6.5pt; vertical-align: -1pt; }
 .s111 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s112 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 8pt; }
 .s113 { color: black; font-family:"Arial Unicode MS", sans-serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 10pt; }
 .s116 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -3pt; }
 .s117 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: -3pt; }
 .s118 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -2pt; }
 .s119 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s120 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s121 { color: #F1F1F2; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s122 { color: #ED1F24; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s123 { color: #ED1F24; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7.5pt; }
 .s124 { color: #ED1F24; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s125 { color: #ED1F24; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7.5pt; }
 .s126 { color: #ED1F24; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s127 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 8pt; }
 .s128 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s129 { color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s130 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -1pt; }
 .s131 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s132 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s133 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s134 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s135 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s136 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; vertical-align: 1pt; }
 .s137 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -4pt; }
 .s138 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7.5pt; vertical-align: -5pt; }
 .s139 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s140 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s141 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; }
 .s142 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s143 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: 3pt; }
 .s144 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; }
 .s145 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -3pt; }
 .s146 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 5pt; }
 .s147 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 1pt; }
 .s148 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; vertical-align: 3pt; }
 .s149 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 3pt; }
 .s150 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -2pt; }
 .s151 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; }
 .s152 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: -2pt; }
 .s153 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; vertical-align: -1pt; }
 .s154 { color: #252525; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 2pt; }
 .s155 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: -1pt; }
 .s156 { color: black; font-family:Helvetica, sans-serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 6pt; }
 h4 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 8pt; }
 li {display: block; }
 #l1 {padding-left: 0pt;counter-reset: c1 1; }
 #l1> li>*:first-child:before {counter-increment: c1; content: counter(c1, upper-latin)". "; color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l1> li:first-child>*:first-child:before {counter-increment: c1 0;  }
 #l2 {padding-left: 0pt; }
 #l2> li>*:first-child:before {content: "• "; color: black; font-family:Menlo, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; }
 li {display: block; }
 #l3 {padding-left: 0pt;counter-reset: d1 5; }
 #l3> li>*:first-child:before {counter-increment: d1; content: counter(d1, upper-roman)". "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l3> li:first-child>*:first-child:before {counter-increment: d1 0;  }
 #l4 {padding-left: 0pt;counter-reset: d2 2; }
 #l4> li>*:first-child:before {counter-increment: d2; content: counter(d2, upper-roman)". "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l4> li:first-child>*:first-child:before {counter-increment: d2 0;  }
 #l5 {padding-left: 0pt;counter-reset: e1 1; }
 #l5> li>*:first-child:before {counter-increment: e1; content: counter(e1, decimal)") "; color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l5> li:first-child>*:first-child:before {counter-increment: e1 0;  }
 #l6 {padding-left: 0pt; }
 #l6> li>*:first-child:before {content: "• "; color: black; font-family:Menlo, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; }
 #l7 {padding-left: 0pt; }
 #l7> li>*:first-child:before {content: "• "; color: black; font-family:Menlo, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; }
 #l8 {padding-left: 0pt; }
 #l8> li>*:first-child:before {content: "• "; color: black; font-family:Menlo, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; }
 #l9 {padding-left: 0pt; }
 #l9> li>*:first-child:before {content: "◦ "; color: black; font-family:"Arial Unicode MS", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l10 {padding-left: 0pt; }
 #l10> li>*:first-child:before {content: "• "; color: black; font-family:Menlo, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 7pt; }
 #l11 {padding-left: 0pt;counter-reset: j1 1; }
 #l11> li>*:first-child:before {counter-increment: j1; content: counter(j1, upper-latin)". "; color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l11> li:first-child>*:first-child:before {counter-increment: j1 0;  }
 #l12 {padding-left: 0pt;counter-reset: j2 1; }
 #l12> li>*:first-child:before {counter-increment: j2; content: counter(j2, decimal)") "; color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l12> li:first-child>*:first-child:before {counter-increment: j2 0;  }
 #l13 {padding-left: 0pt;counter-reset: k1 1; }
 #l13> li>*:first-child:before {counter-increment: k1; content: counter(k1, upper-latin)". "; color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l13> li:first-child>*:first-child:before {counter-increment: k1 0;  }
 #l14 {padding-left: 0pt;counter-reset: k1 2; }
 #l14> li>*:first-child:before {counter-increment: k1; content: counter(k1, upper-latin)". "; color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l14> li:first-child>*:first-child:before {counter-increment: k1 0;  }
 #l15 {padding-left: 0pt;counter-reset: k2 1; }
 #l15> li>*:first-child:before {counter-increment: k2; content: counter(k2, decimal)") "; color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l15> li:first-child>*:first-child:before {counter-increment: k2 0;  }
 #l16 {padding-left: 0pt;counter-reset: l1 1; }
 #l16> li>*:first-child:before {counter-increment: l1; content: counter(l1, upper-latin)". "; color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l16> li:first-child>*:first-child:before {counter-increment: l1 0;  }
 #l17 {padding-left: 0pt;counter-reset: l1 2; }
 #l17> li>*:first-child:before {counter-increment: l1; content: counter(l1, upper-latin)". "; color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l17> li:first-child>*:first-child:before {counter-increment: l1 0;  }
 #l18 {padding-left: 0pt;counter-reset: l2 1; }
 #l18> li>*:first-child:before {counter-increment: l2; content: counter(l2, decimal)") "; color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l18> li:first-child>*:first-child:before {counter-increment: l2 0;  }
 #l19 {padding-left: 0pt;counter-reset: m1 1; }
 #l19> li>*:first-child:before {counter-increment: m1; content: counter(m1, upper-latin)". "; color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l19> li:first-child>*:first-child:before {counter-increment: m1 0;  }
 #l20 {padding-left: 0pt;counter-reset: m2 1; }
 #l20> li>*:first-child:before {counter-increment: m2; content: counter(m2, decimal)") "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l20> li:first-child>*:first-child:before {counter-increment: m2 0;  }
 #l21 {padding-left: 0pt;counter-reset: n1 1; }
 #l21> li>*:first-child:before {counter-increment: n1; content: "("counter(n1, lower-latin)") "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l21> li:first-child>*:first-child:before {counter-increment: n1 0;  }
 #l22 {padding-left: 0pt;counter-reset: o1 1; }
 #l22> li>*:first-child:before {counter-increment: o1; content: "("counter(o1, lower-latin)") "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l22> li:first-child>*:first-child:before {counter-increment: o1 0;  }
 li {display: block; }
 #l23 {padding-left: 0pt;counter-reset: p1 1; }
 #l23> li>*:first-child:before {counter-increment: p1; content: "["counter(p1, decimal)"] "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l23> li:first-child>*:first-child:before {counter-increment: p1 0;  }
 table, tbody {vertical-align: top; overflow: visible; }
</style></head><body><p class="s1" style="padding-top: 7pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">Deep Learning for Rapid Multi-environment Key Generation in FDD-OFDM Systems</p><p class="s2" style="padding-top: 7pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">Xinwei Zhang, Guyue Li, <i>Member, IEEE</i>, Junqing Zhang, Aiqun Hu, <i>Senior Member, IEEE</i></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s4" style="padding-top: 6pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Abstract<span class="h3">—Deep learning-based physical-layer key generation (PKG) for frequency division duplexing (FDD)-orthogonal fre- quency division multiplexing (OFDM) systems has attracted growing attention recently. However, existing works only consider the key generation in a given environment, which is not practical. Training a model in a new environment requires a lot of data and training cost, which is unacceptable for practical applications. Therefore, this paper first proposes a general feature extraction scheme to obtain the suitable feature for key generation. And then aiming at the problems of incompatibility of tasks and poor per- formance of pre-trained network caused by environment changes, this paper proposes the deep transfer learning (DTL) and meta- learning based PKG methods to achieve rapid adaptation in new environments. Simulation results show that compared with the methods without adaptation in the new environments, the DTL and meta-learning algorithms both can improve the performance of generated keys. In addition, the complexity analysis shows that the meta-learning algorithm can achieve better performance than the DTL algorithm with less time, lower CPU and GPU resources.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s4" style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">Index Terms<span class="h3">—Physical-layer key generation, frequency divi- sion duplexing, deep transfer learning, meta learning.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 92pt;text-indent: 0pt;text-align: left;">I. I<span class="s5">NTRODUCTION</span></p><h1 style="text-indent: 0pt;text-align: left;">D</h1><p style="text-indent: 0pt;text-align: left;"/><ol id="l1"><li><p class="s6" style="padding-top: 3pt;padding-left: 19pt;text-indent: -13pt;text-align: justify;">Background</p><p style="padding-top: 3pt;padding-left: 28pt;text-indent: 0pt;text-align: justify;">UE to the openness of wireless channels, the wireless networks are vulnerable to attacks such as eavesdrop-</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">ping, counterfeiting, and tampering, the security of wireless network is hard to guarantee [1]. Traditional security mech- anisms, such as public key cryptography mechanism, are commonly used in current wireless communication systems. However, these security mechanisms face problems such as difficulty in key distribution and inapplicability to large-scale</p><p class="s7" style="padding-top: 8pt;padding-left: 5pt;text-indent: 7pt;text-align: justify;">This work was supported in part by the National Natural Science Foundation of China under Grant 62171121, Grant 61941115, and Grant 61801115; in  part  by  the  Jiangsu  Key Research  and  Development  Plan  under  Grant BE2019109; in part by the Natural Science Foundation of Jiangsu Province under Grant BK20211160; in part by the Social Development Projects of Jiangsu Science and Technology Department under Grant BE2018704; and in part by the Zhishan Youth Scholar Program of Southeast University under Grant 3209012002A3.(<i>Corresponding author: Guyue Li.</i>)</p><p class="s7" style="padding-left: 5pt;text-indent: 7pt;text-align: right;">Xinwei Zhang is with the School of Cyber Science and Engineering, South- east University, Nanjing 210096, China (e-mail: xwzhang1998@gmail.com). Guyue Li is with the School of Cyber Science and Engineering, Southeast University, Nanjing 210096, China, and also with the Purple Mountain Laboratories for Network and Communication Security, Nanjing 210096,</p><p class="s7" style="padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: justify;">China(e-mail: guyuelee@seu.edu.cn).</p><p class="s7" style="padding-left: 5pt;text-indent: 7pt;text-align: justify;">Junqing Zhang is with the Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool L69 3GJ, U.K. (e-mail: junqing.zhang@liverpool.ac.uk).</p><p class="s7" style="padding-left: 5pt;text-indent: 7pt;text-align: justify;">Aiqun Hu is with the School of Information Science and Engineering, and National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China, and also with the Purple Mountain Laboratories for Network and Communication Security, Nanjing 210096, China (e-mail: aqhu@seu.edu.cn).</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">networks with limited resources, which make it difficult to meet the security needs of future wireless communications [2], [3]. In recent years, <i>physical-layer key generation (PKG) </i>has gradually become a research hotspot in the field of wireless communication security. From the perspective of information theory, PKG provides a new security mechanism, which greatly simplifies the distribution and management of keys [2]–[4].</p><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">PKG technology realizes real-time sharing and coordination of random keys by using the short-time reciprocity of uplink and downlink features [2], [5]. The channel features, such as received signal strength (RSS), channel state information (CSI), channel gain, etc., are widely used for PKG [2]. In the time division duplexing (TDD) systems, the uplink and down- link are in the same carrier frequency band, and the channel features obtained by both communication parties is reciprocal. However, in the frequency division duplexing (FDD) systems, due  to  the  uplink  and  downlink  works  on  different  carrier frequency bands, most of the reciprocal channel parameters may be completely different between the uplink and the downlink, thus can not be directly used for key generation. At present, most studies focus on PKG in TDD systems [3], and the research on PKG in FDD systems is still less although the FDD mode is widely used in existing cellular communications, such as LTE and NB-IoT systems [5]–[15]. Therefore, it has profound research value and practical significance to study the PKG method in FDD systems.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s6" style="padding-left: 19pt;text-indent: -13pt;text-align: justify;">Related Work and Problem Statement</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">In resent years, there have been several literatures on the PKG in FDD systems. The authors in [6], [7] proposed to extract the frequency-independent parameters (such as angle, delay and covariance matrix eigenvalues) for PKG. However, these methods have many limits, such as large bandwidth or special configuration of the antenna array [16]. Besides, The authors in [5] proposed a reciprocal channel construction framework named SAR, including separate channel paths, adjust amplitude and phase and reconstruct the channel. But it is difficult to separate the channel paths accurately in the complex multi-path environment. In addition to the above- mentioned method of constructing reciprocal channels by separating paths, some literatures proposed to construct recip- rocal channels by additional reverse channel training, which called the loopback-based methods [8]–[11]. However, these methods require additional backchannel training and multiple iteration interactions, which not only increases the complexity of channel detection, but also has security risks [17].</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="100" height="49" alt="image" src="DTL_KG_files/Image_001.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="264" height="211" alt="image" src="DTL_KG_files/Image_002.png"/></span></p><p class="s9" style="text-indent: 0pt;text-align: left;">Environment (E)</p><p class="s9" style="padding-top: 4pt;text-indent: 0pt;text-align: left;">Secure Connections</p><p style="text-indent: 0pt;text-align: left;"/><p class="s10" style="text-indent: 0pt;text-align: left;">                 <span class="s11">    </span><span class="s9">E3</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s9" style="text-indent: 0pt;text-align: left;">Model 3</p><p style="text-indent: 0pt;text-align: left;"/><p class="s9" style="text-indent: 0pt;text-align: left;">Insecure Connections</p><p style="text-indent: 0pt;text-align: left;"/><p class="s9" style="text-indent: 0pt;text-align: left;">BS (Alice)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s9" style="padding-left: 15pt;text-indent: 0pt;text-align: left;">Model 2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s9" style="text-indent: 0pt;text-align: left;">Model 1</p><p style="text-indent: 0pt;text-align: left;"/><p class="s9" style="text-indent: 0pt;text-align: left;">E2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s9" style="text-indent: 0pt;text-align: left;">E1</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Fig. 1: The Deep learning-based PKG problem in multi- environments.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Due to the excellent performance of deep learning, this technology also be introduced to construct reciprocal channel features for PKG in FDD-orthogonal frequency division mul- tiplexing (OFDM) systems recently [12]–[15], which called <i>deep learning-based key generation methods</i>. In [15], a key generation neural network (KGNet) was proposed for band feature mapping and key generation. A boundary equilibrium generative adversarial network (BEGAN) and an encoder- decoder based convolutional neural network were also pro- posed to predict downlink CSI and key generation [13], [14]. Furthermore, a complex-valued neural network (CVNet) proposed to improve the performance of generated keys. Compared with conventional methods (e.g. [5]–[11]), the deep learning based key generation methods does not limited with channel models and can achieve excellent performance. However, existing deep learning based key generation methods all only consider a given wireless environment and the deep learning model only can learn the given wireless environment. In practice, as shown in Fig. 1, users may experience different new environments. When a user is in a new environment, changes in the environment may lead to degraded or even ineffective performances of the deep learning model due to task mismatch, and thus the base station (BS) cannot provide a secure communication connection without a suitable deep learning model in the new environment. A simple way to solve this problem is to re-collect the data and train the model for each new network environment. However,  training a model requires a lot of data and training time, which is unacceptable for practical applications. Therefore, how to quickly adapt the deep learning model to new environments with low cost to achieve fast key generation is a new problem that needs to be solved.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s6" style="padding-top: 7pt;padding-left: 20pt;text-indent: -14pt;text-align: justify;">Motivations</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Deep transfer learning (DTL) is an effective technology that can solve the problem of task mismatch of the deep learning model caused by environmental changes [18]. Inspired by the transfer ability of human experience, DTL uses the knowledge of source task to improve the performance of target task, and</p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">is a promising machine learning technology that can solve similar tasks with limited labeled data.</p><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">Another effective technique for dealing with task mismatch of the deep learning model is meta-learning [19]. Meta- learning aims to improve learning ability by using different but related training and test data. Most existing meta-learning algorithms are problem-specific. In order to eliminate the limitation of the model architecture on the application of meta- learning, a model-agnostic meta-learning (MAML) algorithm was proposed in [20]. The goal of the algorithm is to achieve fast adaptation by alternately learning the parameter initial- ization of the model between the intra-task process and the cross-task process. In addition, unlike the DTL technology, the MAML algorithm does not need to collect a large amount of data in a fixed environment to pre-train the network, it only needs to collect a small amount of data in multiple environments to train the network. In some cases, it is easier to collect samples from multiple wireless channel environments (each wireless channel environment provides only a small number of samples) than to collect large amounts of data in one fixed environment.</p><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">DTL and meta-learning have been widely used in many areas to solve the mismatch problem of the deep learning model, e.g., channel feedback [21], beam prediction [22], downlink channel prediction [23]. Inspired by these works, this paper uses DTL and meta-learning to achieve fast key generation in the new environments for FDD-OFDM systems.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s6" style="padding-left: 20pt;text-indent: -14pt;text-align: justify;">Main Contributions</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">In this paper, we focus on fast deep learning-based key generation in FDD-OFDM systems. At first, we formulate the fast key generation as a DTL problem and a meta-learning problem. And then we propse a general feature extraction framework, and develop a DTL algorithm and a meta-learning algorithm to achieve fast key generation in FDD systems. We also proposed tow benchmarks, i.e., the direct algorithm and the joint dataset algorithm, to verify the good performance of the algorithms proposed in this paper. Before this paper, there have never been works that focus on the deep learning-based key generation in new environments. Our major contributions are summarized as follows.</p><ul id="l2"><li><p style="padding-top: 2pt;padding-left: 25pt;text-indent: -10pt;text-align: left;">We verify the performance of the method proposed in</p><p style="padding-left: 25pt;text-indent: 0pt;text-align: justify;">[15] in the outdoor scenario and find that the feature extraction method can not be used in the outdoor scenario. Based on this observation, we propose a general feature extraction framework, which can construct suitable fea- tures in the different scenarios.</p></li><li><p style="padding-left: 25pt;text-indent: -10pt;text-align: justify;">We propose a DTL algorithm for fast key generation in FDD systems. By pre-training the model in the source environment, and then fine-tuning the pre-training model in the target new environment with a small number of samples, the DTL algorithm can quickly obtain a better performance model with lower data cost and time cost.</p></li><li><p style="padding-left: 25pt;text-indent: -10pt;text-align: justify;">We propose a meta-learning algorithm for fast key gener- ation in FDD systems. This algorithm no longer requires a lot of data in a single environment to pre-train the model, but uses sample from multiple wireless environments to</p><p style="padding-top: 7pt;padding-left: 25pt;text-indent: 0pt;text-align: justify;">initialize the model. By learning optimal model initial- ization parameters between multiple tasks, the algorithm can be quickly adapted to new environments.</p></li><li><p style="padding-left: 25pt;text-indent: -10pt;text-align: justify;">We verify the proposed algorithms in indoor and outdoor scenarios. The results show the DTL and meta-learning algorithms both can improve performance of generated keys in new environments. In addition, complexity anal- ysis shows that the meta-learning algorithm can achieve better performance with less time, lower CPU and GPU resources, compared with the DTL algorithm.</p></li></ul></li></ol><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">The rest of this paper is structured as follows. The system model for FDD systems is introduced in Section II. In Section III, we prove the possiblity of using deep learning for key generation in FDD systems and formulate the problem as a DTL problem and a meta-learning problem. The DTL algorithm for fast key generation is presented in Section</p><ol id="l3"><li><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">The meta-learning algorithm for fast key generation is presented in Section VI. The simulation results for evaluating the performance of the generated keys and the complexity analysis are provided in Section VII, which is followed by conclusions in Section VIII.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l4"><li><p style="padding-left: 104pt;text-indent: -15pt;text-align: left;">S<span class="s5">YSTEM </span>M<span class="s5">ODEL</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="text-indent: 0pt;line-height: 11pt;text-align: left;">A. Channel Model</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"/><p class="s6" style="padding-top: 7pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">B. Deep Learning-Based Key Generation Scheme</p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">The deep learning technology has been introduced to PKG in FDD systems. This type of method uses deep learning technology to map the uplink features to the downlink features, so that both parties can obtain the downlink features at the same time, which are used as the sources of key generation. The process of this scheme is shown in Fig. 2, including two stages, i.e., preparation stage and key generation stage.</p><ol id="l5"><li><p class="s6" style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">Preparation Stage: <span class="p">In the preparation stage, Alice and Bob perform multiple channel estimations and feature ex- tractions. Alice collects the downlink channel features sent by Bob, and combines the uplink channel features saved by herself to construct a training data set. Then, Alice uses this data set to train a deep learning model, which can then be directly used for key generation.</span></p></li><li><p class="s6" style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">Key Generation Stage: <span class="p">The key generation stage con- tains the following five steps:</span></p></li></ol><ul id="l6"><li><p class="s6" style="padding-top: 1pt;padding-left: 25pt;text-indent: -10pt;text-align: justify;"><span class="p">Step 1: CSI estimation. Alice and Bob simultaneously send OFDM pilot signals to each other at carrier fre- quencies </span>f<span class="s12">dl</span> <span class="p">and </span>f<span class="s12">ul</span><span class="p">, and then independently estimate the channel CFR based on the received pilot signals. The CFR obtained by Alice and Bob can be expressed as</span></p></li></ul><p class="s6" style="padding-left: 25pt;text-indent: 0pt;line-height: 9pt;text-align: left;">, <span class="p">(3)</span></p><p class="s6" style="text-indent: 0pt;line-height: 10pt;text-align: left;">, l<span class="p">)</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s6" style="padding-top: 4pt;padding-bottom: 1pt;padding-left: 54pt;text-indent: 0pt;text-align: left;"><span class="s13"> </span>H<span class="s14">ˆ</span><span class="s15">A </span><span class="p">(</span>f<span class="s12">ul</span>, l<span class="p">) = </span>H <span class="p">(</span>f<span class="s12">ul</span>, l<span class="p">) + </span>E<span class="s16">1</span><span class="s17"> </span><span class="p">(</span>f<span class="s12">ul</span>, l<span class="p">)</span></p><p class="s18" style="text-indent: 0pt;line-height: 80%;text-align: left;">H<span class="p">ˆ</span></p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">B</p><p style="text-indent: 0pt;line-height: 10pt;text-align: left;">(<i>f</i></p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">dl</p><p class="s6" style="text-indent: 0pt;line-height: 10pt;text-align: left;">, l<span class="p">) = </span>H <span class="p">(</span>f</p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">dl</p><p class="s6" style="text-indent: 0pt;line-height: 10pt;text-align: left;">, l<span class="p">) + </span>E</p><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;line-height: 10pt;text-align: left;">(<i>f</i></p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">dl</p><p class="s59" style="padding-left: 62pt;text-indent: 0pt;text-align: left;"> <span style=" color: black; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt;"> </span><span style=" color: black; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt;"> </span><span style=" color: black; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt;"> </span><span style=" color: black; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt;"> </span></p><p class="s6" style="padding-top: 3pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;"><span class="p">This paper considers a FDD-OFDM system, where the BS and users are equipped with a antenna and operate at the FDD mode. Alice and Bob simultaneously transmit signals on different carrier frequencies, </span>f<span class="s12">dl</span> <span class="p">and </span>f<span class="s12">ul</span><span class="p">, respectively. The channel impulse response (CIR) consists of </span>N <span class="p">paths and can be defined as</span></p><p class="s19" style="padding-top: 6pt;text-indent: 0pt;text-align: left;"><span class="s21">          </span>j<span class="s20">2</span>πfτ <span class="s20">+</span>jϕ</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="padding-top: 5pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">N<span class="s22">−</span><span class="s20">1</span></p><p class="s6" style="padding-left: 45pt;text-indent: 0pt;text-align: left;">h<span class="p">(</span>f, τ <span class="p">) = </span>α<span class="s12">n</span>e<span class="s23">−</span><span class="s24"> </span><span class="s25">n n </span>δ<span class="p">(</span>τ <span class="s26">− </span>τ<span class="s12">n</span><span class="p">)</span>, <span class="p">(1)</span></p><p class="s19" style="padding-top: 2pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">n<span class="s20">=0</span></p><p class="s6" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: justify;"><span class="p">where </span>f <span class="p">is the carrier frequency. </span>α<span class="s12">n</span> <span class="p">is the magnitude of the </span>n<span class="s27">th</span> <span class="p">path, which is influenced by the distance </span>d<span class="s12">n</span> <span class="p">between Alice and Bob, the scattering environment and the frequency </span>f <span class="p">. </span>τ<span class="s12">n</span> <span class="p">= </span><span class="s28">d</span><span class="s29">n</span><span class="s30"> </span><span class="p">is the delay of the </span>n<span class="s27">th</span> <span class="p">path, where </span>c <span class="p">is the speed of light.</span></p><p style="padding-top: 6pt;padding-left: 16pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">where  <i>E</i><span class="s16">1</span><span class="s17"> </span>(<i>f</i><i>B</i><i>, l</i>)  and  <i>E</i><span class="s16">2</span><span class="s17"> </span>(<i>f</i><i>A</i><i>, l</i>)  represents  the  channel estimation error, which can be modeled as Additive White Gaussian Noise (AWGN) with mean 0 and variance <i>σ</i><span class="s31">2</span><span class="s17"> </span>. After  channel  estimation,  Alice  and  Bob  get  estimated CFRs <b>H</b><b>ˆ </b><span class="s15">A  </span>and <b>H</b><b>ˆ </b><span class="s15">B </span>, respectively.</p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">E</p><p style="text-indent: 0pt;text-align: left;"/><ul id="l7"><li><p style="padding-left: 16pt;text-indent: -10pt;text-align: justify;">Step 2: Feature extraction. Alice and Bob perform feature extraction to extract real-valued channel features <b>x</b><i>A</i><i> </i>and <b>x</b><i>B</i>. After feature extraction, Alice and bob get channel features <b>x</b><i>A</i><i> </i>and <b>x</b><i>B</i>, respectively.</p></li><li><p style="padding-left: 16pt;text-indent: -10pt;text-align: justify;">Step  3:  Feature  mapping  (only  Alice):  Alice  uses  the pre-trained model to perform feature mapping to get the estimated downlink features <b>xˆ</b><i>B</i>.</p></li><li><p style="padding-left: 16pt;text-indent: -10pt;line-height: 12pt;text-align: justify;">Step 4: Key generation: Alice and Bob use estimated</p></li></ul><p class="s19" style="padding-left: 9pt;text-indent: 0pt;line-height: 1pt;text-align: left;">c</p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 10pt;text-align: left;">ϕ<span class="s12">n</span> <span class="p">is the phase shift of the </span>n<span class="s27">th</span></p><p style="padding-left: 1pt;text-indent: 0pt;text-align: left;">path, which is determined by</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">downlink features to generate keys, including quantifica-</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 4pt;text-align: left;">tion, information reconciliation and privacy amplification</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">the scatterer(s) materials and wave incident/impinging angles at the scatterer(s).</p><p class="s6" style="padding-left: 5pt;text-indent: 9pt;text-align: left;"><span class="p">In FDD-OFDM systems, the channel frequency response (CFR) of the </span>l<span class="s27">th</span> <span class="p">sub-carrier can be expressed as</span></p><p class="s19" style="padding-top: 6pt;text-indent: 0pt;text-align: left;"><span class="s21">          </span>j<span class="s20">2</span>πfτ <span class="s20">+</span>jϕ j<span class="s20">2</span>πτ l/L</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="padding-top: 7pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">N<span class="s22">−</span><span class="s20">1</span></p><p class="s6" style="padding-left: 42pt;text-indent: 0pt;text-align: left;">H<span class="p">(</span>f, l<span class="p">) = </span>α<span class="s12">n</span>e<span class="s23">−</span><span class="s24"> </span><span class="s25">n n </span>e<span class="s23">−</span><span class="s24"> </span><span class="s25">n </span>, <span class="p">(2)</span></p><p class="s19" style="padding-top: 2pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">n<span class="s20">=0</span></p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{ − }</p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">×</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">where <i>L </i>is the number of subcarriers. We define the 1 <i>L </i>channel vector <b>H</b>(<i>f </i>) = <i>H</i>(<i>f, </i>0)<i>, ..., H</i>(<i>f, L </i>1) as the CFR of frequency <i>f </i>, and <b>H</b><i>A</i><i> </i>= <b>H</b>(<i>f</i><i>ul</i>) as the CFR of <i>f</i><i>ul</i>, <b>H</b><i>B</i><i> </i>= <b>H</b>(<i>f</i><i>dl</i>) as the CFR of <i>f</i><i>dl</i>. As shown in (2), the amplitude and phase of wireless channel <b>H</b>(<i>f </i>) are influenced by frequency. Since wireless signals travel the same paths on uplink and downlink, the channels <b>H</b><i>A</i><i> </i>and <b>H</b><i>B</i><i> </i>are almost different in FDD systems. Therefore, how to extract or construct the reciprocal channel features for key generation in FDD systems is a big challenge.</p><p style="padding-top: 7pt;padding-left: 25pt;text-indent: 0pt;text-align: justify;">[24]. We use the quantization method proposed in [15] to get the initial keys <b>Q</b><i>A</i><i> </i>and <b>Q</b><i>B</i>.</p><p style="padding-left: 25pt;text-indent: 0pt;text-align: justify;">Information reconciliation and privacy amplification methods adopted by most key generation methods are mostly common. In addition, the research purpose of this paper is to improve the channel reciprocity in the FDD system, thus this paper only compares the performance of the initial keys after quantization and does not carry out the steps of information reconciliation and privacy amplification after quantization.</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">The good performance of this scheme depends on the per- formance of the deep learning model. The existing papers have verifies the good fitting and generalization performance of deep learning model in a certain environment [15]. However, when the environments changes, this scheme may lead to the problem of task mismatch, and the performance of the deep learning model will be greatly reduced. Thus, this paper aims</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="684" height="164" alt="image" src="DTL_KG_files/Image_003.png"/></span></p><p class="s34" style="text-indent: 0pt;line-height: 7pt;text-align: left;"><span class="s33">{</span>x<i>A</i><i>, </i>x<i>B</i><span class="s33">}</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s37" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">CSI Feature</p><p class="s37" style="text-indent: 0pt;text-align: left;">Estimation    <span class="s38">H</span><span class="s39">ˆ </span><span class="s40">A        </span>Extration</p><p style="text-indent: 0pt;text-align: left;"/><p class="s37" style="padding-left: 19pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Data Set</p><p class="s41" style="text-indent: 0pt;line-height: 91%;text-align: left;">x<span class="s42">A </span><span class="s37">Generation</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s37" style="padding-left: 2pt;text-indent: 0pt;line-height: 9pt;text-align: left;">Model <span class="s43">NET</span></p><p class="s37" style="text-indent: 0pt;line-height: 8pt;text-align: left;">Training</p><p style="text-indent: 0pt;text-align: left;"/><p class="s37" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">CSI</p><p class="s37" style="text-indent: 0pt;text-align: left;">Estimation    <span class="s38">H</span><span class="s39">ˆ </span><span class="s40">A</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s37" style="text-indent: 2pt;text-align: left;">Feature Extration</p><p style="text-indent: 0pt;text-align: left;"/><p class="s8" style="text-indent: 0pt;line-height: 8pt;text-align: left;">K<span class="s44">A</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s45" style="text-indent: 0pt;line-height: 7pt;text-align: left;">x<i>A</i></p><p style="text-indent: 0pt;text-align: left;"/><p class="s37" style="text-indent: 2pt;text-align: left;">Feature Mapping</p><p style="text-indent: 0pt;text-align: left;"/><p class="s37" style="padding-left: 24pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Key</p><p class="s47" style="text-indent: 0pt;line-height: 85%;text-align: left;">x<span class="s48">ˆ</span><span class="s42">B    </span><span class="s37">generation</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s49" style="text-indent: 0pt;line-height: 9pt;text-align: left;">Alice</p><p style="text-indent: 0pt;text-align: left;"/><p class="s50" style="text-indent: 0pt;line-height: 8pt;text-align: left;">f<span class="s51">dl </span>f<span class="s51">ul</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s45" style="text-indent: 0pt;line-height: 7pt;text-align: left;">x<i>B</i></p><p style="text-indent: 0pt;text-align: left;"/><p class="s50" style="text-indent: 0pt;line-height: 8pt;text-align: left;">f<span class="s51">dl </span>f<span class="s51">ul</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s37" style="text-indent: 0pt;line-height: 8pt;text-align: center;">CSI</p><p class="s37" style="text-indent: 0pt;line-height: 8pt;text-align: center;">Estimation</p><p style="text-indent: 0pt;text-align: left;"/><p class="s52" style="text-indent: 0pt;line-height: 8pt;text-align: left;">H<span class="s53">ˆ </span><span class="s54">B</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s37" style="text-indent: 2pt;text-align: left;">Feature <span class="s55">Extration </span><span class="s45">x</span><span class="s46">B</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s37" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">CSI</p><p class="s37" style="text-indent: 0pt;text-align: left;">Estimation    <span class="s38">H</span><span class="s39">ˆ </span><span class="s40">B</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s37" style="text-indent: 2pt;text-align: left;">Feature Extration</p><p style="text-indent: 0pt;text-align: left;"/><p class="s8" style="text-indent: 0pt;line-height: 8pt;text-align: left;">K<span class="s44">B</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s45" style="text-indent: 0pt;line-height: 7pt;text-align: left;">x<i>B</i></p><p style="text-indent: 0pt;text-align: left;"/><p class="s37" style="text-indent: 8pt;text-align: left;">Key generation</p><p style="text-indent: 0pt;text-align: left;"/><p class="s49" style="text-indent: 0pt;line-height: 9pt;text-align: left;">Bob</p><p style="text-indent: 0pt;text-align: left;"/><p class="s56" style="text-indent: 0pt;line-height: 10pt;text-align: left;">Preparation Stage</p><p style="text-indent: 0pt;text-align: left;"/><p class="s56" style="text-indent: 0pt;line-height: 10pt;text-align: left;">Key Generation Stage</p><p style="text-indent: 0pt;text-align: left;"/><p class="s58" style="padding-left: 1pt;text-indent: 0pt;text-align: left;"><span class="s57">.</span>0<span class="s59"> </span>1…<span class="s59"> </span>1<span class="s59"> </span>0<span class="s59"> </span>1…</p><p style="text-indent: 0pt;text-align: left;"/><p class="s58" style="padding-left: 1pt;text-indent: 0pt;text-align: left;"><span class="s57">.</span>0<span class="s59"> </span>1…<span class="s59"> </span>1<span class="s59"> </span>0<span class="s59"> </span>1…</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">Fig. 2: Deep learning-based key generation scheme for FDD systems.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">to quickly apply the pre-trained model to a new environment with low training cost.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">C. Metrics</p><ul id="l8"><li><p class="s6" style="padding-top: 3pt;padding-left: 25pt;text-indent: -10pt;text-align: left;">Normalized Mean Square Error (NMSE)<span class="p">: The is used to evaluate the predictive accuracy of the network, which is</span></p></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">deep learning model directly. We propose a feature extraction function <span class="s60">ξ </span>to preprocess <b>H</b>. Denote the inverse function of <span class="s60">ξ </span>as <span class="s60">ξ</span><span class="s23">−</span><span class="s31">1</span>, we can obtain the following theorem.</p><p class="s6" style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">Theorem 1: <span class="p">For any given error </span>ε &gt; <span class="p">0, there exists a positive constant </span>M <span class="p">large enough such that</span></p><p class="s61" style="text-indent: 0pt;line-height: 8pt;text-align: left;">f    <span class="s62">→</span>f<span class="s63">ul</span><span class="s64">          dl</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 19pt;text-indent: 0pt;line-height: 13pt;text-align: left;">sup <span class="s26">∥ </span><b>NET</b><i>M</i><i> </i>(<b>x</b>(<i>f</i><i>ul</i>)<i>, </i><b>Ω</b>) <span class="s26">− </span><b>Ψ</b><span class="s65">′                    </span>(<b>x</b>(<i>f</i><i>ul</i>)) <span class="s26">∥≤ </span><i>ε,</i></p><p style="padding-left: 25pt;text-indent: 0pt;text-align: left;">defined as</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 8pt;text-indent: 0pt;line-height: 8pt;text-align: left;">NMSE = <i>E</i></p><p class="s26" style="padding-top: 6pt;padding-bottom: 1pt;text-indent: 0pt;text-align: left;"><span class="s66">＿</span>∥ <span class="h2">x</span> <span class="s12">B</span><span class="s6"> </span>− <span class="h2">x</span><span class="s12">B</span><span class="s6"> </span>∥<span class="s67">2 </span><span class="s66">＿</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="77" height="1" alt="image" src="DTL_KG_files/Image_004.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="padding-left: 47pt;text-indent: 0pt;line-height: 7pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="text-indent: 0pt;line-height: 8pt;text-align: left;">, <span class="p">(4)</span></p><p class="s68" style="padding-left: 22pt;text-indent: 0pt;line-height: 8pt;text-align: left;">x<span class="s22">∈</span><span class="s20">H</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">1</p><p style="padding-left: 71pt;text-indent: 0pt;line-height: 7pt;text-align: left;"/><p style="padding-top: 8pt;padding-left: 25pt;text-indent: 0pt;text-align: left;"><span class="s17">H </span>= <span class="s26">{</span><b>x</b>(<i>f</i><i>ul</i>)<span class="s26">}</span><i>,</i></p><p class="s69" style="padding-top: 5pt;padding-left: 8pt;text-indent: 0pt;line-height: 2pt;text-align: center;">′</p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 10pt;text-align: left;">(6)</p><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="padding-left: 86pt;text-indent: 0pt;line-height: 9pt;text-align: right;">∥ <span class="h2">x</span><span class="s12">B</span><span class="s6"> </span>∥<span class="s67">2</span></p><p style="padding-left: 85pt;text-indent: 0pt;line-height: 8pt;text-align: left;">where the channel feature mapping function <b>Ψ</b></p><p class="s22" style="padding-left: 16pt;text-indent: 0pt;line-height: 7pt;text-align: center;">−</p><p class="s61" style="text-indent: 0pt;line-height: 6%;text-align: left;">f<span class="s63">ul</span><span class="s62">→</span>f<span class="s63">dl</span></p><p style="padding-left: 1pt;text-indent: 0pt;text-align: left;">= <span class="s60">ξ</span><span class="s70">f</span><span class="s71">dl </span><span class="s26">◦</span></p><p style="padding-left: 25pt;text-indent: 0pt;line-height: 10pt;text-align: left;">where <i>E </i>[<span class="s26">·</span>] represents the expectation operation.</p><p class="s32" style="padding-left: 25pt;text-indent: 0pt;text-align: left;">Ψ<span class="s61">f</span><span class="s63">ul</span></p><p class="s22" style="text-indent: 0pt;line-height: 10pt;text-align: left;">→<span class="s19">f</span><span class="s72">dl</span></p><ul id="l9"><li><p class="s60" style="padding-left: 10pt;text-indent: -8pt;text-align: left;">ξ<span class="s73">f</span><span class="s74">dl</span></p><p style="padding-left: 3pt;text-indent: 0pt;line-height: 10pt;text-align: left;">: <b>x</b>(<i>f</i><i>ul</i>) <span class="s26">→ </span><b>x</b>(<i>f</i><i>dl</i>), <b>NET</b><i>M</i><i> </i>(<b>x</b>(<i>f</i><i>ul</i>)) is the</p><ul id="l10"><li><p class="s6" style="padding-left: 25pt;text-indent: -10pt;line-height: 5pt;text-align: left;">Key Error Rate (KER)<span class="p">: It is defined as the number of</span></p><p style="padding-left: 25pt;text-indent: 0pt;line-height: 7pt;text-align: justify;">error bits divided by the number of total key bits.</p></li><li><p class="s6" style="padding-left: 25pt;text-indent: -10pt;text-align: justify;">Key Generation Ratio (KGR)<span class="p">: It is defined as the number of initial key bits divided by the number of subcarriers.</span></p></li><li><p class="s6" style="padding-left: 25pt;text-indent: -10pt;text-align: justify;">Randomness<span class="p">: The randomness reveals the distribution of bit streams. The National Institute of Standards and Technology (NIST) statistical test [25] is used for the randomness test for the generated keys.</span></p></li></ul></li></ul></li><li><p style="padding-top: 8pt;padding-left: 87pt;text-indent: -19pt;text-align: left;">P<span class="s5">ROBLEM </span>F<span class="s5">ORMULATION</span></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">In this section, we first prove the possibility of using deep learning to construct reciprocal channel features for key generation in FDD systems. Then, we formula the question of how to transfer one model in a certain environment to other</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: justify;">output of a feedforward neural network (FNN) with only one</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 4pt;text-align: justify;">hidden layer. <b>x</b>(<i>f</i><i>ul</i>), <b>Ω </b>and <i>M </i>denote the input data, network</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">parameters, and the number of hidden units, respectively.</p><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">Theorem 1 reveals that the channel feature mapping function can be obtained by a simple deep learning model in a given environment. However, as the model may can not be used in other environments or a dynamic environment. This challenge can be formulated by a DTL problem and a meta-learning problem that leverage existing knowledge to improve model performance in new environments.</p><p class="s6" style="padding-top: 8pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">B. DTL Problem for PKG</p><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">1</p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Assume that there are data in <i>E </i>wireless scenarios, and the uplink and downlink channel characteristics in the <i>e</i><i>th</i></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">different environments efficiently.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">environment are defined as <b>x</b><i>e</i></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">and <b>x</b><i>e</i></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">respectively. The</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">A. Deep Learning for Reciprocal Feature Construction</p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 9pt;line-height: 12pt;text-align: justify;">Since the uplink and the downlink transmissions travel the same propagation paths and suffer the same cluster in a given environment, there exists a channel mapping function between different frequency bands [15]. The channel mapping function</p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="p">”domain” and ”task” in the </span>e<span class="s27">th</span> <span class="p">environment are defined as following:</span></p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">A</p><p style="text-indent: 0pt;text-align: left;"/><p class="s64" style="text-indent: 0pt;line-height: 5pt;text-align: left;">A</p><p style="text-indent: 0pt;text-align: left;"/><p class="s64" style="text-indent: 0pt;line-height: 5pt;text-align: left;">A</p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">D</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">A</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;"><span class="s75">Definition </span><i>1 (Domain): </i>The domain (<i>e</i>) is composed of the uplink channel features <b>x</b><i>e</i><i> </i>and the marginal probability distribution <i>P</i><span class="s76">x</span><span class="s77">e </span>, i.e., <span class="s26">D</span>(<i>e</i>) = <span class="s26">{</span><b>x</b><i>e</i><i> , P</i><span class="s76">x</span><span class="s77">e </span><span class="s26">}</span>.</p><p style="padding-left: 15pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s75">Definition </span><i>2 (Task): </i>The task <span class="s26">T </span>(<i>e</i>) is composed of the</p><p style="padding-left: 268pt;text-indent: 0pt;line-height: 0pt;text-align: left;">downlink channel features <b>x</b><i>e</i><i> </i>and the feature mapping func-</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">can be written as</p><p class="s19" style="text-indent: 0pt;line-height: 5pt;text-align: center;">B</p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">e</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">B</p><p style="text-indent: 0pt;text-align: left;"/><p class="s12" style="text-indent: 0pt;line-height: 10pt;text-align: left;">e<span class="s26">}</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">tion <i>F </i>, i.e., <span class="s26">T </span>(<i>e</i>) = <span class="s26">{</span><b>x</b><i>e</i><i> , F </i>.</p><h2 style="text-indent: 0pt;line-height: 12pt;text-align: left;">Ψ<span class="s70">f</span></h2><p style="text-indent: 0pt;text-align: left;"/><p class="s64" style="padding-top: 9pt;padding-left: 86pt;text-indent: 0pt;text-align: right;">ul<span class="s62">→</span><span class="s61">f</span><span class="s63">dl</span></p><p style="padding-top: 2pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">: <b>H</b>(<i>f</i><i>ul</i>) <span class="s26">→ </span><b>H</b>(<i>f</i><i>dl</i>)<i>. </i>(5)</p><p style="padding-left: 9pt;text-indent: 9pt;line-height: 93%;text-align: left;"><span class="s75">Remark </span><i>1: </i>According to theorem 1, it is assumed that in a certain environment (domain <span class="s26">D</span><i>SE</i><i> </i>and task <span class="s26">T</span><i>SE</i>), the feature</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">As shown in (2), the channel mapping function can not be expressed as mathematical formulas, deep learning technology can be used to approach this mapping function. At first, we only consider a simple three-layers fully connected neural network (FNN) with one hidden layer.</p><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">Since the CFRs are in complex domain and are not in a certain range, the value of CFRs could not be used to train the</p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="p">mapping function </span>F<span class="s12">k</span> <span class="p">can be obtained by model training. Trained networks can act as this function to achieve the feature band mapping. However, when the environment changes, the feature mapping function </span>F<span class="s12">e</span> <span class="p">will also change, the performance of the previously trained model will be greatly reduced in the new environment, and the consistency of the features obtained by both parties will also be greatly reduced. Therefore, how</span></p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">D T</p><p style="text-indent: 0pt;text-align: left;"/><p class="s6" style="padding-top: 7pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="p">to quickly apply the trained </span>F<span class="s12">e</span> <span class="p">to another new environment (domain  </span><span class="s12">T</span> <span class="s12">E</span> <span class="p">and task </span><span class="s12">T</span> <span class="s12">E</span><span class="p">) is the main problem to be solved in this paper.</span></p><p class="s12" style="padding-left: 5pt;text-indent: 9pt;text-align: right;"><span class="p">Based on [18], this problem can be formulated as a DTL problem, and the definition of DTL can be given as following: </span><span class="s75">Definition </span><span class="s6">3 (Deep transfer learning): </span><span class="p">Given the source domain </span><span class="s26">D</span>SE<span class="p">, the source task </span><span class="s26">T</span>SE<span class="p">, the target domain </span><span class="s26">D</span>T<span class="s6"> </span>E<span class="s6"> </span><span class="p">and the target task </span><span class="s26">T</span>T<span class="s6"> </span>E<span class="p">, transfer learning aims to leverage</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 6pt;text-align: justify;">knowledge of <span class="s26">D </span>and <span class="s26">T </span>to improve performance on target</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">6</p><p style="text-indent: 0pt;text-align: left;"><span><img width="130" height="95" alt="image" src="DTL_KG_files/Image_005.png"/></span></p><p class="s79" style="text-indent: 0pt;line-height: 67%;text-align: left;">10<span class="s80">-4</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s78" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">Amplitude</p><p style="text-indent: 0pt;text-align: left;"/><p class="s78" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">5</p><p class="s78" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">4</p><p class="s78" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">3</p><p class="s78" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">2</p><p class="s78" style="padding-top: 5pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">0             20            40            60</p><p class="s78" style="padding-left: 25pt;text-indent: 0pt;text-align: center;">Index</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">6</p><p style="text-indent: 0pt;text-align: left;"><span><img width="129" height="95" alt="image" src="DTL_KG_files/Image_006.png"/></span></p><p class="s79" style="text-indent: 0pt;line-height: 67%;text-align: left;">10<span class="s80">-4</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s81" style="text-indent: 0pt;line-height: 6pt;text-align: left;">Real Part Imaginary Part</p><p style="text-indent: 0pt;text-align: left;"/><p class="s78" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">4</p><p class="s78" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">Value</p><p style="text-indent: 0pt;text-align: left;"/><p class="s78" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">2</p><p class="s78" style="padding-top: 4pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">0</p><p class="s78" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">-2</p><p class="s78" style="padding-top: 4pt;padding-left: 25pt;text-indent: 0pt;line-height: 7pt;text-align: center;">-4</p><p class="s78" style="padding-left: 25pt;text-indent: 0pt;line-height: 7pt;text-align: center;">0              50            100           150</p><p class="s78" style="padding-left: 25pt;text-indent: 0pt;text-align: center;">Index</p><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;line-height: 0pt;text-align: left;">task</p><p class="s19" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">SE SE</p><p class="s7" style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 3pt;text-align: left;">(a) The amplitude of CFR in the indoor(b) The real and imaginary parts of CFR</p><p class="s12" style="padding-left: 26pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s26">T</span>T<span class="s6"> </span>E<span class="p">, where </span><span class="s26">T</span>T<span class="s6"> </span>E<span class="s6"> </span><span class="s26">T</span>SE<span class="s6"> </span><span class="p">and </span><span class="s26">D</span>T<span class="s6"> </span>E<span class="s6"> </span><span class="s26"≯</span><span class="p">= </span><span class="s26">D</span>SE<span class="p">. When the</span></p><p class="s7" style="padding-top: 5pt;padding-left: 9pt;text-indent: 0pt;line-height: 6pt;text-align: left;">scenario.</p><p class="s7" style="padding-top: 5pt;padding-left: 26pt;text-indent: 0pt;line-height: 6pt;text-align: left;">in the indoor scenario.</p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="p">feature mapping function </span>F<span class="s12">T</span> <span class="s12">E</span> <span class="p">is a non-linear function that can be learned by a deep learning model, the transfer learning task </span>&lt; <span class="s26">D</span><span class="s12">SE</span>, <span class="s26">T</span><span class="s12">SE</span>, <span class="s26">D</span><span class="s12">T</span> <span class="s12">E</span>, <span class="s26">T</span><span class="s12">T</span> <span class="s12">E</span> &gt; <span class="p">is a DTL task.</span></p><p class="s6" style="padding-top: 16pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">C. Meta-Learning Problem for PKG</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Meta-learning, as another effective technique to deal with the task mismatch problem, learns the initialization values of the model from multiple tasks. Therefore, based on [26],</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">2</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="125" height="95" alt="image" src="DTL_KG_files/Image_007.png"/></span></p><p class="s79" style="text-indent: 0pt;line-height: 67%;text-align: left;">10<span class="s80">-5</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s78" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">Amplitude</p><p style="text-indent: 0pt;text-align: left;"/><p class="s78" style="padding-left: 86pt;text-indent: 0pt;text-align: right;">1.5</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="text-indent: 0pt;text-align: right;">1</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-left: 86pt;text-indent: 0pt;text-align: right;">0.5</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-left: 11pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0</p><p class="s78" style="padding-left: 15pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0 50 100 150</p><p class="s78" style="padding-left: 55pt;text-indent: 0pt;line-height: 6pt;text-align: left;">Index</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="130" height="95" alt="image" src="DTL_KG_files/Image_008.png"/></span></p><p class="s79" style="text-indent: 0pt;line-height: 67%;text-align: left;">10<span class="s80">-5</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s81" style="text-indent: 0pt;line-height: 6pt;text-align: left;">Real Part Imaginary Part</p><p style="text-indent: 0pt;text-align: left;"/><p class="s78" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">Value</p><p style="text-indent: 0pt;text-align: left;"/><p class="s78" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">1</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-left: 8pt;text-indent: 0pt;text-align: left;">0</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">-1</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-left: 25pt;text-indent: 0pt;line-height: 7pt;text-align: center;">-2</p><p class="s78" style="padding-left: 25pt;text-indent: 0pt;line-height: 7pt;text-align: center;">0             100           200           300</p><p class="s78" style="padding-left: 25pt;text-indent: 0pt;line-height: 6pt;text-align: center;">Index</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">the problem that we aim to solve in this paper also can be</p><p class="s7" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 6pt;text-align: left;">(c) The amplitude of CFR in the outdoor(d) The real and imaginary parts of CFR</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">formulated as a meta-learning problem, and the definition of</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;">DTL can be given as following:</p><p class="s7" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">scenario.</p><p class="s7" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">in the outdoor scenario.</p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">e<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 9pt;line-height: 90%;text-align: left;"><span class="s75">Definition </span><i>4 (Meta-learning): </i>Given the number of source tasks <i>E</i><i>S</i>, the source domains <span class="s26">{D</span><i>SE</i>(<i>e</i>)<span class="s26">}</span><span class="s82">E</span><span class="s30">s </span>, the source</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Fig. 3: The different features in the indoor and outdoor scenarios.</p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">e<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">tasks<span class="s26">{T</span><i>SE</i>(<i>e</i>)<span class="s26">}</span><span class="s82">E</span><span class="s30">s </span>, the target domains <span class="s26">D</span><i>T</i><i> </i><i>E</i><i> </i>and the target</p><p class="s61" style="text-indent: 0pt;line-height: 7pt;text-align: left;">E<span class="s63">s</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s61" style="text-indent: 0pt;line-height: 7pt;text-align: left;">E<span class="s63">s</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s61" style="text-indent: 0pt;line-height: 7pt;text-align: left;">E<span class="s63">s</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s61" style="text-indent: 0pt;line-height: 7pt;text-align: left;">E<span class="s63">s</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">T T {T } D {D }</p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{D } {T }</p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">T</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 11pt;text-indent: -5pt;text-align: right;">tasks <i>T</i><i> </i><i>E</i>, meta learning aims to leverage knowledge of <i>SE</i>(<i>e</i>) <span class="s70">e</span><span class="s83">=1 </span>and <i>SE</i>(<i>e</i>) <span class="s70">e</span><span class="s83">=1 </span>to learn how to learn new task <span class="s15">TE </span>, where <span class="s15">TE SE </span>(<i>e</i>) <span class="s70">e</span><span class="s83">=1 </span>and <span class="s15">TE SE </span>(<i>e</i>) <span class="s70">e</span><span class="s83">=1</span>.</p><p class="s75" style="padding-left: 15pt;text-indent: 0pt;line-height: 10pt;text-align: justify;">Remark <span class="s6">2 (DTL vs. Meta-learning): </span><span class="p">Transfer learning needs</span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">a large amount of data in one source environment to train the model, while meta-learning requires data from multiple source environments, and the amount of data in each environment is small. When there are data sets from multiple environments and the amount of data in each scenario is small, meta-learning is obviously an optimal choice compared to DTL. When there is a large amount of data in only one scenario, meta-learning techniques can be employed by dividing the source scenario into multiple task scenarios. The simulation results in Section VII show that meta-learning is still better than DTL in this case.</p></li><li><p style="padding-top: 10pt;padding-left: 15pt;text-indent: 7pt;line-height: 16pt;text-align: justify;">F<span class="s5">EATURE </span>E<span class="s5">XTRACTION </span><span class="s7">FOR </span>K<span class="s5">EY </span>G<span class="s5">ENERATION </span>Firstly, we could process the estimated CFRs to obtain the</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">suitable features for PKG in FDD systems. In [15], feature ex- traction includes two steps, i.e., realization and normalization. Through the observation, we find that the realization method in [15] is not suitable in the outdoor scenario. Therefore, this paper proposes a general feature extraction framework for key generation in different scenarios.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l11"><li><p class="s6" style="padding-left: 19pt;text-indent: -13pt;text-align: justify;">Observation</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">In [15], the features used for key generation are the real and imaginary parts of the CFR, and simulations only verify the  performance in  the indoor  scenario. This  paper further collects data in the outdoor scenario to verify the performance and finds that the same feature extraction method is no longer suitable for use in the outdoor scenario. As shown</p><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">in Fig. 3, in the indoor scenario, the channel multipaths and scatterers are not abundant enough, the variation of channel amplitudes is not obvious, and it is difficult for the deep learning model to learn the mapping relationship between the waveforms with little variation. Therefore, in the indoor environment, the real and imaginary parts of CFR are selected as the features for generating keys, which has two advantages. One is that features with significant fluctuations can improve the randomness of the generated keys, and the other is that quantizing the real and imaginary parts separately can improve the KGR. In the outdoor scenario, the channel environment is more complex, and the amplitude and phase changes are more obvious, resulting in excessive fluctuations of the real and imaginary parts of the superimposed CFR, and it is difficult for the deep learning model to learn the mapping between the waveforms with excessive changes. Meanwhile, the variability of channel amplitudes in outdoor scenes is sufficient, so the amplitude of the CFR should be selected as the features for key generation.</p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">In summary, according to different scenarios, different fea- ture extraction methods should be selected to obtain the most suitable features for band mapping and key generation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s6" style="padding-left: 19pt;text-indent: -13pt;text-align: left;">The General Feature Extraction Framewrok</p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Based on the observation, we proposed a general feature extraction framework, as shown in Fig. 4. This scheme in- cludes two steps, i.e., realization and normalization, and we choose the suitable realization method according to the degree of fluctuation of different features.</p><ol id="l12"><li><p class="s6" style="padding-top: 2pt;padding-left: 29pt;text-indent: -13pt;text-align: justify;">Realization: <span class="p">The realization have two methods.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s84" style="padding-left: 86pt;text-indent: 0pt;line-height: 62%;text-align: right;">10<span class="s85">-5</span></p><p class="s86" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">The imaginary part</p><p style="text-indent: 0pt;text-align: left;"/><p class="s86" style="padding-left: 5pt;text-indent: 0pt;line-height: 3pt;text-align: center;">2</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s86" style="padding-left: 5pt;text-indent: 0pt;text-align: center;">1</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s86" style="padding-left: 5pt;text-indent: 0pt;text-align: center;">0</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s86" style="padding-left: 25pt;text-indent: 0pt;text-align: center;">-1</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s87" style="padding-left: 4pt;text-indent: 0pt;text-align: left;">CFR</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s87" style="padding-left: 19pt;text-indent: 0pt;text-align: left;">Channel Features</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="56" height="43" alt="image" src="DTL_KG_files/Image_009.png"/></span></p><p class="s86" style="padding-left: 13pt;text-indent: 0pt;text-align: left;">0.06</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s86" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">Value</p><p style="text-indent: 0pt;text-align: left;"/><p class="s86" style="padding-left: 13pt;text-indent: 0pt;text-align: left;">0.04</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s86" style="padding-left: 13pt;text-indent: 0pt;text-align: left;">0.02</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s88" style="padding-left: 86pt;text-indent: 0pt;text-align: right;">Input layer</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s88" style="padding-left: 13pt;text-indent: 0pt;text-align: left;">Hidden Layers</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s88" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">Output Layer</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s86" style="padding-left: 13pt;text-indent: 0pt;line-height: 3pt;text-align: left;">-2</p><p class="s86" style="padding-left: 15pt;text-indent: 0pt;line-height: 3pt;text-align: left;">-2 -1 0 1 2</p><p class="s89" style="padding-top: 1pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">   </p><p style="text-indent: 0pt;text-align: left;"/><p class="s89" style="padding-top: 1pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">   </p><p style="text-indent: 0pt;text-align: left;"/><p class="s90" style="padding-left: 31pt;text-indent: 0pt;text-align: left;">The real part <span class="s86">10</span><span class="s91">-5</span></p><p class="s87" style="padding-top: 16pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">Realization</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s86" style="padding-left: 13pt;text-indent: 0pt;line-height: 3pt;text-align: left;">0</p><p style="text-indent: 0pt;text-align: left;"><span><img width="11" height="14" alt="image" src="DTL_KG_files/Image_010.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="59" height="40" alt="image" src="DTL_KG_files/Image_011.jpg"/></span></p><p class="s86" style="padding-left: 15pt;text-indent: 0pt;line-height: 3pt;text-align: left;">0 50 100 150</p><p class="s86" style="padding-left: 33pt;text-indent: 0pt;text-align: left;">Index</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s92" style="padding-left: 86pt;text-indent: 0pt;text-align: right;">x<span class="s93">A</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="151" height="91" alt="image" src="DTL_KG_files/Image_012.png"/></span></p><p class="s89" style="text-indent: 0pt;text-align: left;">   </p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="58" height="38" alt="image" src="DTL_KG_files/Image_013.jpg"/></span></p><p class="s89" style="padding-top: 1pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">   </p><p style="text-indent: 0pt;text-align: left;"/><p class="s89" style="padding-top: 1pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">   </p><p style="text-indent: 0pt;text-align: left;"/><p class="s92" style="padding-left: 22pt;text-indent: 0pt;text-align: center;">xˆ<span class="s93">B</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="242" height="95" alt="image" src="DTL_KG_files/Image_014.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="2" height="2" alt="image" src="DTL_KG_files/Image_015.png"/></span></p><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Fig. 4: The general feature extraction framework, including two steps, i.e., realization and normalization.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">Method 1<span class="p">: Separating real and imaginary parts from </span>H<span class="p">, i.e.,</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 86pt;text-indent: 0pt;text-align: right;"><b>x</b><span class="s31">(1)</span><span class="s17"> </span><span class="s26">← </span>(<span class="s17">R</span>(<b>H</b>)<i>, </i><span class="s17">T</span>(<b>H</b>))<i>, </i>(7)</p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">· ·</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 12pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">where <span class="s17">R</span>( ) and <span class="s17">T</span>( ) denote the real and imaginary parts of a matrix, vectors or scales, respectively.</p><h2 style="padding-top: 1pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">Method 2<span class="p">: Calculating the amplitude of </span>H<span class="p">, i.e.,</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 86pt;text-indent: 0pt;text-align: right;">x<span class="s31">(1)</span><span class="s17"> </span><span class="s26">← ||</span>H<span class="s26">||</span><span class="s16">2</span><i>, </i><span class="p">(8)</span></h2><p style="padding-top: 11pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">where <span class="s26">∥ · ∥</span><span class="s16">2</span><span class="s17"> </span>denotes the <i>L</i><span class="s16">2</span><span class="s17"> </span>norm.</p><p class="s75" style="padding-top: 1pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Remark <span class="s6">3 (Method 1 vs. Method 2): </span><span class="p">These two methods are suitable for different wireless environments, when the wireless environment is complex, it is suitable to use method 1, and when the wireless environment changes slowly, it is suitable to use method 2. In practise, we should try these two methods to observe the degree of fluctuation of the features to choose the most suitable method.</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">It should be emphasized that the two realization methods are used in this paper in the indoor and outdoor scenarios, respectively. In practice, these two methods can be tried in many different scenarios, depending on the degree of channel variation in the real environment.</p></li><li><p class="s6" style="padding-top: 1pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Normalization: <span class="p">Normalization is commonly used to nor- malize the data set so that the range of the data set is between 0 and 1. The minimum and maximum values of the vector s in each dimension after realization using the training dataset are saved for min-max normalization,</span></p></li></ol></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 72pt;text-indent: 0pt;text-align: left;">Fig. 5: Network architecture.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l13"><li><p class="s6" style="padding-top: 9pt;padding-left: 19pt;text-indent: -13pt;text-align: justify;">Network Architecture</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">This  paper  considers  a  simple  FNN  to  learn  the  feature mapping  function,  as  shown  in  Fig.  5.  The  FNN  consists  of <i>M  </i>layers.  The  input  of  the  network  is  the  uplink  channel feature  vector  <b>x</b><i>A</i><i>  </i>obtained  by  Alice,  and  the  output  of  the network is the result of the cascade of <b>x</b><i>A</i><i>  </i>through nonlinear transformation.  The  network  is  used  to  map  the  features  of the  uplink  and  downlink,  so  the  output  of  the  network  is considered  to  be  the  estimated  vector  <b>xˆ</b><i>B</i><i>  </i>of  the  downlink channel feature vector <b>x</b><i>B</i>, which can be expressed as:</p><p style="padding-top: 9pt;padding-left: 90pt;text-indent: 0pt;text-align: left;"><b>x</b>ˆ<i>B</i><i> </i>= <b>NET</b>(<b>x</b><i>B</i><i>, </i><b>Ω</b>)<i>,                           </i>(10)</p><p style="padding-top: 10pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">where Ω is all parameters in this network to be trained. The output <i>f</i><i>m</i>(<b>x</b>) of the <i>m</i><i>th</i><i> </i>layer can be written as:</p><p style="padding-left: 5pt;text-indent: 36pt;line-height: 21pt;text-align: left;"><i>f</i><i>m</i>(<b>x</b>) = <i>F</i><i>A,m</i>(<b>W</b><i>m</i><b>x </b>+ <b>b</b><i>m</i>)<i>, </i>2 <span class="s26">≤ </span><i>m </i><span class="s26">≤ </span><i>M, </i>(11) where <i>F</i><i>A,m</i>, <b>W</b><i>m</i><i> </i>and <b>b</b><i>m</i><i> </i>are activation function of <i>m</i><i>th</i></p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">−</p><p style="text-indent: 0pt;text-align: left;"/><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="p">layer, weight between (</span>m <span class="p">1)</span><span class="s27">th</span> <span class="p">and </span>m<span class="s27">th</span> <span class="p">layers and bias vector of </span>m<span class="s27">th</span> <span class="p">layer, respectively. The rectified linear unit (ReLU) function commonly used in regression problems is selected as the activation function </span>F<span class="s12">A,m</span> <span class="p">of the hidden layers, and the sigmoid function is selected as the activation function </span>F<span class="s12">A,m</span> <span class="p">of the output layer.</span></p><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">The  purpose  of  the  network  is  to  learn  the  band  feature mapping, so we could train network to minimize the difference between  network  output  <b>x</b>ˆ<i>B</i><i>  </i>and  <b>x</b><i>B</i>.  Obsoletely,  a  vector regression  problem  is  considered  in  this  paper,  we  consider to  use  the  mean  squared  error  (MSE)  as  the  loss  function  of</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-left: 86pt;text-indent: 0pt;line-height: 2pt;text-align: right;">(1)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="padding-left: 86pt;text-indent: 0pt;line-height: 4pt;text-align: right;">(1)</p><p style="padding-left: 25pt;text-indent: 0pt;line-height: 10pt;text-align: center;">the neural network. The loss function is defined as:</p><h2 style="padding-left: 72pt;text-indent: 0pt;line-height: 5pt;text-align: left;">x <span class="s26">− </span><span class="p">min(</span>x<span class="s94">train</span><span class="s95">) </span><span class="s73">n</span><span class="s63">d</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 57pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="135" height="1" alt="image" src="DTL_KG_files/Image_016.png"/></span></p><p class="s19" style="padding-top: 5pt;padding-left: 72pt;text-indent: 0pt;line-height: 1pt;text-align: left;">N <span class="s22">−</span><span class="s20">1</span></p><p class="s96" style="padding-left: 37pt;text-indent: 0pt;line-height: 3pt;text-align: left;">x <span class="s97">= </span><span class="s20">(1)</span></p><p class="s20" style="padding-left: 86pt;text-indent: 0pt;line-height: 3pt;text-align: right;">(1)</p><p class="s6" style="padding-left: 6pt;text-indent: 0pt;line-height: 3pt;text-align: left;">, <b>x </b><span class="s26">∈ </span><span class="p">[0</span>, <span class="p">1]</span></p><p class="s6" style="padding-left: 7pt;text-indent: 0pt;line-height: 3pt;text-align: left;">, <span class="p">(9)</span></p><p class="s64" style="padding-left: 37pt;text-indent: 0pt;line-height: 11%;text-align: left;"><span class="s98">     1     </span><span class="s99">    </span>ba<span class="s100"> </span>tch</p><p class="s20" style="padding-left: 86pt;text-indent: 0pt;line-height: 2pt;text-align: right;">(<span class="s19">i</span>)</p><p class="s20" style="padding-left: 16pt;text-indent: 0pt;line-height: 2pt;text-align: left;">(<span class="s19">i</span>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="padding-left: 31pt;text-indent: 0pt;line-height: 7pt;text-align: left;"/><p style="padding-left: 25pt;text-indent: 0pt;text-align: center;">max(<b>x</b><span class="s94">train</span><span class="s95">) </span><span class="s26">− </span>min(<b>x</b><span class="s94">train</span><span class="s95">)</span></p><p style="padding-top: 11pt;padding-left: 25pt;text-indent: 0pt;line-height: 8pt;text-align: center;">where <b>x </b>is the normalized value of <i>n</i><i>d</i><i> </i>dimensions.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><i>Loss</i><span class="s16">D</span>(<b>Ω</b>) =</p><p class="s101" style="padding-left: 1pt;text-indent: 0pt;line-height: 6pt;text-align: left;">N<span class="s102">batch</span></p><p class="s19" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">i<span class="s20">=0</span></p><p class="s26" style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;">∥<span class="h2">x</span> <span class="s12">B</span></p><p class="s26" style="padding-left: 3pt;text-indent: 0pt;text-align: left;">− <span class="h2">x</span><span class="s73">B</span></p><p class="s26" style="padding-left: 1pt;text-indent: 0pt;line-height: 1pt;text-align: left;">∥<span class="s103">2</span><span class="s6">, </span><span class="p">(12)</span></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">With these two steps, we can get features with values in the range of 0 to 1. The processed features facilitate the subsequent learning of deep learning models and key generation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ol></li><li><p style="padding-top: 8pt;padding-left: 37pt;text-indent: -14pt;text-align: left;">DTL A<span class="s5">LGORITHM </span><span class="s7">FOR </span>F<span class="s5">AST </span>K<span class="s5">EY </span>G<span class="s5">ENERATION</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">where <span class="s17">D </span>= (<b>x</b><i>A</i><i>, </i><b>x</b><i>B</i>) <i>N</i><span class="s104">batch</span><span class="s105">−</span><span class="s103">1 </span>is a batch-sized training dataset, <i>N</i><i>batch</i><i> </i>is the batch size, the superscript (<i>i</i>) denotes the index of the <i>i</i>-th training sample.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">i<span class="s20">=0</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{ }</p><p style="text-indent: 0pt;text-align: left;"/><ol id="l14"><li><p class="s6" style="padding-left: 19pt;text-indent: -13pt;text-align: left;">Definition of Dataset</p><p style="padding-top: 4pt;padding-left: 15pt;text-indent: 0pt;text-align: left;">Denote the original dataset in a source environment <span class="s17">D</span><i>OS</i><i> </i>=</p><p class="s20" style="padding-left: 286pt;text-indent: 0pt;line-height: 1pt;text-align: left;">(<span class="s19">n</span>) (<span class="s19">n</span>) <span class="s19">N</span><span class="s72">S</span></p><p style="padding-top: 1pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Based on the DTL problem formulated in Section III-B, this section first introduces the structure of the network, and then proposes a DTL algorithm to achieve fast key generation in new scenarios for FDD-OFDM systems.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s26">{</span>(<b>H</b><span class="s73">A </span><i>, </i><b>H</b><span class="s73">B </span>)<span class="s26">}</span><i>n</i><span class="s16">=1</span>, including <i>N</i><i>S</i><i> </i>samples, and the dataset</p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">A</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">B</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{ }</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">after feature extraction as <span class="s17">D</span><i>S</i><i> </i>= (<b>x</b><span class="s31">(</span><i>n</i><span class="s31">)</span><i>, </i><b>x</b><span class="s31">(</span><i>n</i><span class="s31">)</span>) <i>N</i><span class="s104">S </span>. De- note the original dataset in <i>E</i><i>T</i><i> </i>target environments as</p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">e<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s26">{</span><span class="s17">D</span><span class="s12">OT</span> <span class="p">(</span>e<span class="p">)</span><span class="s26">}</span><span class="s82">E</span><span class="s30">T </span><span class="p">, where the dataset of </span>e<span class="s27">th</span> <span class="p">environment as</span></p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">A B n<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 6pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s17">D</span><i>OT</i><i> </i>(<i>e</i>) = <span class="s26">{</span>(<b>H</b><span class="s31">(</span><i>n</i><span class="s31">)</span>(<i>e</i>)<i>, </i><b>H</b><span class="s31">(</span><i>n</i><span class="s31">)</span>(<i>e</i>))<span class="s26">}</span><span class="s82">N</span><span class="s30">T</span></p><p class="s6" style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><span class="p">, including </span>N<span class="s12">T</span> <span class="p">sam-</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="335" height="1" alt="image" src="DTL_KG_files/Image_017.png"/></span></p><h2 style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">Algorithm 1 <span class="p">The DTL algorithm for fast key generation in FDD systems</span></h2><p style="padding-left: 5pt;text-indent: 0pt;line-height: 2pt;text-align: left;">ples, and the dataset after feature extraction as <span class="s17">D</span><i>T</i><i> </i>(<i>e</i>) =     <u>                                                                                                     </u></p><p class="s20" style="padding-left: 20pt;text-indent: 0pt;line-height: 1pt;text-align: left;">(<span class="s19">n</span>) (<span class="s19">n</span>) <span class="s19">N</span><span class="s72">T</span></p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{ }</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;line-height: 13pt;text-align: left;">(<b>x</b><span class="s73">A </span>(<i>e</i>)<i>, </i><b>x</b><span class="s73">B </span>(<i>e</i>)) <span class="s70">n</span><span class="s83">=1</span>.</p><p class="s12" style="padding-left: 15pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="p">In DTL algorithm, the training dataset </span><span class="s17">D</span>T<span class="s6"> </span>r<span class="s6"> </span><span class="p">is considered</span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">as the dataset <span class="s17">D</span><i>S</i><i> </i>in the source environment. The dataset</p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s17">D</span><span class="s12">T</span> <span class="p">(</span>e<span class="p">) in the target environment divides into adaption dataset</span></p><h2 style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Input:</h2><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">e<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">e<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;line-height: 89%;text-align: justify;">The training dataset in a source environment: <span class="s17">D</span><i>T</i><i> </i><i>r</i>, the adaption dataset in target environments: <span class="s26">{</span><span class="s17">D</span><i>Ad</i>(<i>e</i>)<span class="s26">}</span><span class="s82">E</span><span class="s30">T </span>, the testing dataset in target environments: <span class="s26">{</span><span class="s17">D</span><i>T</i><i> </i><i>e</i>(<i>e</i>)<span class="s26">}</span><span class="s82">E</span><span class="s30">T </span>,</p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">A</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">B</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 5pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s17">D</span><i>Ad</i>(<i>e</i>) = <span class="s26">{</span>(<b>H</b><span class="s31">(</span><i>n</i><span class="s31">)</span>(<i>e</i>)<i>, </i><b>H</b><span class="s31">(</span><i>n</i><span class="s31">)</span>(<i>e</i>))<span class="s26">}</span><span class="s82">N</span><span class="s30">Ad </span>and testing dataset</p><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">(<span class="s19">n</span>) (<span class="s19">n</span>)</p><p style="text-indent: 0pt;text-align: left;"/><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="s17">D</span><span class="s12">T</span> <span class="s12">e</span><span class="p">(</span>e<span class="p">) = </span><span class="s26">{</span><span class="p">(</span><b>H </b><span class="p">(</span>e<span class="p">)</span>, <b>H </b><span class="p">(</span>e<span class="p">))</span><span class="s26">}</span><span class="s82">N</span><span class="s30">T </span><span class="s25">e </span><span class="p">, where </span>N<span class="s12">Ad</span> <span class="p">+ </span>N<span class="s12">T</span> <span class="s12">e</span> <span class="p">=</span></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">learning rate: <i>γ</i>, batch size: <i>N</i><i>batch</i>, the number of the gradient update in fine-tuning stage: <i>G</i><i>Ad</i></p><p class="s6" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">N<span class="s12">T</span> <span class="p">.</span></p><p class="s19" style="padding-left: 5pt;text-indent: 0pt;line-height: 38%;text-align: left;">A B n<span class="s20">=1</span></p><h2 style="padding-left: 5pt;text-indent: 0pt;text-align: left;">Output:</h2><p style="padding-left: 19pt;text-indent: 0pt;text-align: left;">The trained parameters of pre-trained model: Ω, the</p></li><li><p class="s6" style="padding-top: 5pt;padding-left: 20pt;text-indent: -14pt;text-align: left;">DTL Algorithm</p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Transfer learning transfers knowledge from the source do- main to the target domain, so that the network in target domain can achieves a better learning effect. In general, dataset in the source domain is abundant, while datasets in the target domains are small. In order to achieve fast key generation in FDD systems, this paper proposes a DTL algorithm, which uses the dataset in the source domain to train a pre-trained model, and then uses a small number of samples to fine- tune the pre-trained model to obtain a model with good performance in the new environments. The DTL algorithm includes three steps, i.e., pre-training stage, fine-tuning stage and testing stage. The DTL algorithm is given in the Algorithm 1.</p><ol id="l15"><li><p class="s6" style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">Pre-training Stage: <span class="p">The pre-training stage trains the model using dataset </span><span class="s17">D</span><span class="s12">T</span> <span class="s12">r</span> <span class="p">in the source environment to min-</span></p><p style="padding-left: 21pt;text-indent: 0pt;text-align: justify;">trained  parameters  in  each  target  environment:  Ω<i>e</i>,  the predicted  downlink  features:  <b>x</b>ˆ<i>B</i>,  the  average  NMSE  of target environments: NMSE</p><p class="s7" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">1: <span class="s75">Pre-training stage</span></p><p class="s7" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">2: <span class="p">Randomly initialize the network parameters Ω;</span></p><h2 style="padding-left: 9pt;text-indent: 0pt;text-align: left;"><span class="s7">3: </span>for <span class="p">t=1,... </span>do</h2><p class="s6" style="padding-left: 9pt;text-indent: 0pt;text-align: left;"><span class="s7">4: </span><span class="p">Randomly select </span>N<span class="s12">batch</span> <span class="p">samples from </span><span class="s17">D</span><span class="s12">T</span> <span class="s12">r</span> <span class="p">to construct</span></p><p class="s107" style="padding-left: 31pt;text-indent: 0pt;line-height: 12pt;text-align: left;">D<span class="s19">TrB </span><span class="s108">;</span></p><p style="padding-left: 31pt;text-indent: -21pt;text-align: left;"><span class="s7">5: </span>Update Ω using the ADAM [27] algorithm ( learning rate <i>γ</i>) to minimize <i>Loss</i><span class="s16">D</span><span class="s109">T rB </span>(<b>Ω</b>);</p><p class="s7" style="padding-left: 9pt;text-indent: 0pt;line-height: 10pt;text-align: left;">6: <span class="h2">end for</span></p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">←−</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 9pt;text-indent: 0pt;text-align: left;"><span class="s7">7: </span>Initialize NMSE<i>total</i><i> </i>0;</p><p class="s6" style="padding-left: 9pt;text-indent: 0pt;text-align: left;"><span class="s7">8: </span><b>for </b>e <span class="p">= 1</span>, ..., E<span class="s12">T</span> <b>do</b></p><p class="s7" style="padding-left: 9pt;text-indent: 0pt;text-align: left;">9: <span class="s75">Fine-tuning stage</span></p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">←−</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s7">10: </span>Initialize the network parameters Ω<i>k</i><i> </i>Ω;</p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s7">11: </span><b>for </b>j <span class="p">= 1</span>, ..., G<span class="s12">Ad</span> <b>do</b></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="s7">12: </span>Randomly select <i>N</i><i>batch</i><i> </i>samples from <span class="s17">D</span><i>Ad</i>(<i>k</i>) to</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">imize the loss function <i>Loss</i><span class="s16">D</span><span class="s109">T r </span>(<b>Ω</b>). In each batch, <i>N</i><i>batch</i></p><p class="s12" style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="p">samples are randomly selected from </span><span class="s17">D</span>T<span class="s6"> </span>r<span class="s6"> </span><span class="p">to construct a batch</span></p><p style="padding-top: 3pt;padding-left: 41pt;text-indent: 0pt;text-align: left;">construct <span class="s17">D</span><i>AdB</i>;</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="s7">13: </span>Update Ω<i>e</i><i> </i>using the ADAM algorithm ( learning rate</p><p class="s12" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="p">training dataset </span><span class="s17">D</span>T<span class="s6"> </span>rB<span class="p">, and then ADAM [27] optimizer is used to optimize the parameters of the model. When the performance of the model tends to be constant or the number</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 4pt;text-align: justify;">of iterations reaches the upper limit, the parameters Ω of the</p><p class="s6" style="padding-top: 3pt;padding-left: 41pt;text-indent: 0pt;text-align: left;">γ<span class="p">) to minimize </span>Loss<span class="s16">D</span></p><p class="s7" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">14: <span class="h2">end for</span></p><p class="s7" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">15: <span class="s75">Testing stage</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s64" style="text-indent: 0pt;text-align: left;">AdB</p><p style="padding-top: 3pt;text-indent: 0pt;text-align: left;">(<b>Ω</b><span class="s110">e</span>);</p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">pre-trained model is obtained.</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s7">16:       </span><span class="s111">Predict the downlink features </span><b>x</b>ˆ<i>B</i><i>  </i>using Eq. (10);</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="s7">17: </span>Calculate NMSE(<i>e</i>) using Eq. (4);</p></li><li><p class="s6" style="padding-left: 29pt;text-indent: -13pt;line-height: 11pt;text-align: left;">Fine-tuning Stage: <span class="p">For the </span>e<span class="s27">th</span> <span class="p">target environment, the</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 4pt;text-align: left;">parameters Ω of the pre-trained model are used to initialize</p><p class="s7" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">18: <span class="p">NMSE</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">total</p><p class="s26" style="padding-top: 2pt;padding-left: 1pt;text-indent: 0pt;line-height: 13pt;text-align: left;">←− <span class="p">NMSE</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">total</p><p style="padding-top: 4pt;text-indent: 0pt;text-align: left;">+ NMSE(<i>e</i>);</p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;">the network model parameter Ω<i>e</i><i> </i>in the target environment. Then the parameter</p><p class="s7" style="padding-left: 7pt;text-indent: 0pt;line-height: 11pt;text-align: left;">19: <span class="h2">end for</span></p><p class="s106" style="padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s112"> 20: </span>NMSE <span class="s113">←− </span>NMSE<i>total</i><i>/E</i><i>T</i><i> </i>;                                              </p><p style="padding-left: 87pt;text-indent: 0pt;line-height: 0pt;text-align: left;">Ω<i>e</i><i> </i>is optimized using the adaptive dataset</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s17">D</span><i>Ad</i>(<i>e</i>) in the target environment to minimize <i>Loss</i><span class="s16">D</span><span class="s109">Ad </span>(<b>Ω</b>). When the performance of the model tends to be constant or the number of iterations reaches the upper limit, the parameters Ω<i>e</i><i> </i>of the model in a new environment is obtained.</p></li><li><p class="s6" style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">Testing Stage: <span class="p">The network parameter Ω</span><span class="s12">e</span> <span class="p">is fixed, and the network is directly used in the feature mapping step in the target environment. We calculate the NMSE in the </span>e<span class="s27">th</span> <span class="p">scenario using the testing dataset </span><span class="s17">D</span><span class="s12">T</span> <span class="s12">e</span><span class="p">(</span>e<span class="p">).</span></p></li></ol></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l16"><li><p class="s6" style="padding-left: 19pt;text-indent: -13pt;text-align: justify;">Definition of Dataset</p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">E<span class="s72">S</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Since meta-learning requires learning model initializa- tion from multiple tasks, datasets need to be collected from multiple source environments. Assume that the dataset</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s26">{</span><span class="s17">D</span><i>OS</i>(<i>e</i>)<span class="s26">}</span><i>e</i><span class="s16">=1</span><span class="s17"> </span>is collected from <i>E</i><i>S</i><i> </i>source environments,</p><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">1</p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">(<span class="s19">n</span>) (<span class="s19">n</span>)</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 5pt;text-indent: 0pt;line-height: 13pt;text-align: left;">where the dataset <span class="s17">D</span><i>OS</i>(<i>e</i>) = <span class="s26">{</span>(<b>H </b>(<i>e</i>)<i>, </i><b>H </b>(<i>e</i>))<span class="s26">}</span><span class="s82">N</span><span class="s30">S</span></p><p class="s6" style="padding-left: 5pt;text-indent: 9pt;text-align: justify;"><span class="p">After repeating the fine-tuning and testing stages in </span>E<span class="s12">T</span> <span class="p">target environments, we calculate the average NMSE of target environments to evaluate the performance of the proposed DTL algorithm.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ol></li><li><p style="padding-left: 103pt;text-indent: -79pt;text-align: left;">M<span class="s5">ETA</span>-L<span class="s5">EARNING </span>A<span class="s5">LGORITHM </span><span class="s7">FOR </span>F<span class="s5">AST </span>K<span class="s5">EY </span>G<span class="s5">ENERATION</span></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Based on the meta-learning problem formulated in Section III-C, this section proposed a meta-learning algorithm to achieve fast key generation in FDD-OFDM systems. We first introduce the definition of dataset, and then introduce the proposed meta-learning algorithm in detail.</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">includes <i>N</i><i>S</i><i> </i>samples in the <i>e</i><i>th</i><i> </i>environment, and the dataset is obtained after feature extraction <span class="s17">D</span><i>S</i>(<i>e</i>) = (<b>x </b>(<i>e</i>)<i>, </i><b>x </b>(<i>e</i>)) . Furthermore, it is necessary to col- lect dataset in multiple target environments to evaluate the performance of the algorithm. Collect datasets <span class="s17">D</span><i>OT</i><i> </i>(<i>e</i>) <i>E</i><span class="s104">T </span>from <i>E</i><i>T</i><i> </i>target environments, where the data in the <i>e </i>environment<span class="s17">D</span><i>OT</i><i> </i>(<i>e</i>) = (<b>H </b>(<i>e</i>)<i>, </i><b>H </b>(<i>e</i>)) <i>N</i><span class="s104">T </span>includes <i>N</i><i>T</i><i> </i>data samples, and the dataset is obtained after feature extraction <span class="s17">D</span><i>T</i><i> </i>(<i>e</i>) = <span class="s26">{</span>(<b>x </b>(<i>e</i>)<i>, </i><b>x </b>(<i>e</i>))<span class="s26">}</span><span class="s82">N</span><span class="s30">T </span>.</p><p class="s20" style="text-indent: 0pt;line-height: 8pt;text-align: left;">(<span class="s19">n</span>) (<span class="s19">n</span>) <span class="s19">N</span><span class="s72">S</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">e<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{ }</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">e<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{ }</p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">1</p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">1</p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">1</p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{ }</p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">(<span class="s19">n</span>) (<span class="s19">n</span>)</p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{ }</p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">(<span class="s19">n</span>) (<span class="s19">n</span>)</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">In meta-learning, the training set <span class="s17">D</span><i>T</i><i> </i><i>r</i><i> </i>is the data set in the source environment <span class="s17">D</span><i>OS</i>(<i>e</i>) <i>E</i><span class="s104">S </span>. The training set needs to be divided into support set <span class="s17">D</span><i>Su</i>(<i>e</i>) and query set <span class="s17">D</span><i>Qu</i>(<i>e</i>), and</p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">∩ ∅</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="s20">(</span>n<span class="s20">) (</span>n<span class="s20">) </span>N<span class="s72">T</span> <span class="s72">e</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">1</p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">n<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">(<span class="s19">n</span>) (<span class="s19">n</span>) <span class="s19">N</span><span class="s72">Ad</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">must satisfy <span class="s17">D</span><i>Su</i>(<i>e</i>) <span class="s17">D</span><i>Qu</i>(<i>e</i>) = . The dataset <span class="s17">D</span><i>T</i><i> </i>(<i>e</i>) in the target environment is to be divided into an adaptation set <span class="s17">D</span><i>Ad</i>(<i>e</i>) = <span class="s26">{</span>(<b>H </b>(<i>e</i>)<i>, </i><b>H </b>(<i>e</i>))<span class="s26">} </span>and test set <span class="s17">D</span><i>T</i><i> </i><i>e</i>(<i>e</i>) =</p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;line-height: 14pt;text-align: justify;"><span class="s26">{</span><span class="p">(</span><b>H</b><span class="s83">1 </span><span class="p">(</span>e<span class="p">)</span>, <b>H</b><span class="s83">2 </span><span class="p">(</span>e<span class="p">))</span><span class="s26">}</span><span class="s12">n</span><span class="s16">=1</span><span class="p">, where </span>N<span class="s12">Ad</span> <span class="p">+ </span>N<span class="s12">T</span> <span class="s12">e</span> <span class="p">= </span>N<span class="s12">T</span> <span class="p">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l17"><li><p class="s6" style="padding-left: 19pt;text-indent: -13pt;text-align: left;">Meta-Learning Algorithm</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="335" height="1" alt="image" src="DTL_KG_files/Image_018.png"/></span></p><h2 style="padding-bottom: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Algorithm 2 <span class="p">The meta-learning algorithm for fast key gener- ation in FDD systems</span></h2><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="335" height="1" alt="image" src="DTL_KG_files/Image_019.png"/></span></p><h2 style="padding-left: 9pt;text-indent: 0pt;line-height: 11pt;text-align: left;">Input:</h2><p style="padding-left: 22pt;text-indent: 0pt;line-height: 8pt;text-align: left;">The training support dataset: <span class="s26">{</span><span class="s17">D</span><i>Su</i>(<i>e</i>)<span class="s26">}</span><span class="s82">E</span><span class="s30">S </span>, the train-</p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">The meta-learning algorithm require to train the model under multiple source tasks, and then adapt and test in new environment. It is mainly divided into meta-training, meta- adaptation, and meta-testing stages. The meta-learning algo- rithm is given in the Algorithm 2.</p><ol id="l18"><li><p class="s6" style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">Meta-Training Stage: <span class="p">During the meta-training phase, the goal of the meta-learning algorithm is to learn a network initialization that can effectively adapt to new tasks. First, the parameters Ω of KGNet are randomly initialized, and then updated through two iterative processes, namely intra- task update and cross-task update. The network parameters of each source task are optimized within the task update, and the</span></p><p style="padding-top: 3pt;padding-bottom: 1pt;padding-left: 22pt;text-indent: 0pt;line-height: 2pt;text-align: left;">ing query dataset:<span class="s26">{</span><span class="s17">D </span><i>E</i><span class="s104">S</span></p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">E</p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">}</p><p style="padding-left: 63pt;text-indent: 0pt;text-align: left;">	</p><p class="s19" style="padding-left: 22pt;text-indent: 0pt;line-height: 5pt;text-align: left;">e<span class="s20">=1</span></p><p style="padding-left: 22pt;text-indent: 0pt;line-height: 5pt;text-align: left;">global neural network is optimized across the task update.</p><p style="padding-left: 22pt;text-indent: 0pt;line-height: 0pt;text-align: left;"><span class="s26">{</span><span class="s17">D</span><i>Ad</i>(<i>e</i>)<span class="s26">}</span></p><p style="padding-left: 49pt;text-indent: 0pt;text-align: left;"><i>Qu</i>(<i>e</i>) <span class="s70">e</span><span class="s83">=1</span>, the adaption dataset:</p><p style="padding-left: 3pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="s25">T </span>, the testing dataset: <span class="s26">{</span><span class="s17">D</span><i>T</i><i> </i><i>e</i>(<i>e</i>)<span class="s26">}</span><span class="s82">E</span><span class="s30">T </span>, inner-task</p><h2 style="padding-left: 19pt;text-indent: 0pt;line-height: 0pt;text-align: left;">Intra-task update<span class="p">: A batch of </span><i>E</i></h2><p class="s19" style="text-indent: 0pt;line-height: 0pt;text-align: left;">batch</p><p style="padding-left: 3pt;text-indent: 0pt;line-height: 0pt;text-align: left;">tasks is randomly</p><p class="s19" style="padding-left: 86pt;text-indent: 0pt;line-height: 2pt;text-align: right;">e<span class="s20">=1</span></p><p class="s19" style="padding-left: 86pt;text-indent: 0pt;line-height: 2pt;text-align: right;">e<span class="s20">=1</span></p><p class="s6" style="padding-left: 54pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span class="p">selected from </span>E<span class="s12">S</span> <span class="p">environments at a time. The goal of each</span></p><p style="padding-left: 22pt;text-indent: 0pt;line-height: 7pt;text-align: justify;">learning rate: <i>α</i>, across-task learning rate: <i>γ</i>, batch size</p><p class="s6" style="padding-left: 22pt;text-indent: 0pt;text-align: justify;"><span class="p">for meta-training: </span>E<span class="s12">batch</span><span class="p">, batch size for meta-adaption: </span>N<span class="s12">batch</span> <span class="p">the number of gradient update for inner-task train- ing: </span>G<span class="s12">T</span> <span class="s12">r</span><span class="p">, the number of the gradient update in fine-tuning stage: </span>G<span class="s12">Ad</span></p><h2 style="padding-left: 9pt;text-indent: 0pt;line-height: 12pt;text-align: left;">Output:</h2><p style="padding-left: 22pt;text-indent: 0pt;text-align: justify;">The   trained   parameters   of   pre-trained   model:   Ω,   the trained  parameters  in  each  target  environment:  Ω<i>e</i>,  the predicted  downlink  features:  <b>x</b>ˆ<i>B</i>,  the  average  NMSE  of target environments: NMSE</p><p class="s7" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">1: <span class="s75">Meta-training stage</span></p><p class="s7" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">2: <span class="p">Initialize the network parameters Ω;</span></p><h2 style="padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s7">3: </span>for <span class="p">t=1,... </span>do</h2><p class="s6" style="padding-left: 32pt;text-indent: -21pt;text-align: left;"><span class="s7">4: </span><span class="p">Randomly select </span>E<span class="s12">batch</span> <span class="p">environments form </span>E<span class="s12">S</span> <span class="p">source environments;</span></p><p style="padding-top: 3pt;padding-left: 9pt;text-indent: 0pt;text-align: justify;">task is to optimize its own neural network parameters on its support data set <span class="s17">D</span><i>Su</i>(<i>e</i>). The objective of each task is achieved by minimizing the loss function based on supervised learning. The objective function of each task can be expressed as:</p><p class="s20" style="text-indent: 0pt;line-height: 7pt;text-align: left;">Ω</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 6pt;padding-left: 17pt;text-indent: 0pt;line-height: 13pt;text-align: justify;">Ω<i>S,e</i><i> </i>= arg min <i>Loss</i><span class="s16">D</span><span class="s116">Su</span><span class="s83">(</span><span class="s70">e</span><span class="s83">) </span>(Ω<i>S,e</i>) <i>, e </i>= 1<i>, . . . , E</i><i>B</i><i>, </i><span class="s117">(13)</span></p><p class="s64" style="padding-left: 71pt;text-indent: 0pt;line-height: 5pt;text-align: left;">S,e</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-left: 9pt;text-indent: 0pt;text-align: justify;"><span class="p">where Ω</span><span class="s12">S,e</span> <span class="p">is the network parameter of the </span>e<span class="s27">th</span> <span class="p">task in the source task set. Specifically, Ω</span><span class="s12">S,e</span> <span class="p">is initialized to Ω, and is then updated with </span>G<span class="s12">T</span> <span class="s12">r</span> <span class="p">times of gradient descent, i.e.,</span></p><p class="s6" style="padding-top: 2pt;padding-left: 9pt;text-indent: 36pt;line-height: 20pt;text-align: left;"><b>Ω</b><span class="s12">S,e</span> <span class="s26">← </span><b>Ω</b><span class="s12">S,e</span> <span class="s26">− </span>α<span class="s26">∇</span><span class="s76">Ω</span><span class="s109">S,e </span><span class="p">Loss</span><span class="s16">D</span><span class="s118">Su</span><span class="s119">(</span><span class="s15">e</span><span class="s120">) </span><span class="p">(</span><b>Ω</b><span class="s12">S,e</span><span class="p">) </span>, <span class="p">(14) where </span>α <span class="p">is the learning rate between tasks.</span></p><p style="padding-top: 1pt;padding-left: 19pt;text-indent: 0pt;text-align: justify;">In the original MAML algorithm, intra-task updates were</p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">e<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{ }</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 11pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s7">5: </span>Generate support dataset <span class="s17">D</span><i>Su</i>(<i>e</i>) <i>E</i><span class="s104">batch</span></p><p style="text-indent: 0pt;line-height: 12pt;text-align: left;">dataset     <span class="s26">{</span><span class="s17">D      </span>(<i>e</i>)<span class="s26">} </span>;<i>Qu</i></p><p style="text-indent: 0pt;text-align: left;"/><p class="s61" style="padding-left: 105pt;text-indent: 0pt;line-height: 80%;text-align: left;">E<span class="s63">batch </span><span class="s19">e</span><span class="s20">=1</span></p><p class="s6" style="padding-left: 11pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s7">6: </span><b>for </b>e <span class="p">= 1</span>, ..., E<span class="s12">batch</span> <b>do</b></p><p style="padding-left: 4pt;text-indent: 0pt;text-align: left;">and query</p><p style="padding-left: 9pt;text-indent: 0pt;line-height: 10pt;text-align: left;">made only once. And then some literatures proposed to</p><p style="padding-left: 9pt;text-indent: 0pt;text-align: left;">increase the times of intra-task update to improve the perfor- mance. This paper analyzes the impact of task update times</p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">←−</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s7">7: </span>Initialize the network parameters Ω<i>S,e</i><i> </i>Ω;</p><p class="s6" style="padding-left: 11pt;text-indent: 0pt;text-align: left;"><span class="s7">8: </span><b>for </b>i <span class="p">= 1</span>, ..., G<span class="s12">T</span> <span class="s12">r</span> <b>do</b></p><p style="padding-left: 52pt;text-indent: -41pt;text-align: left;"><span class="s7">9: </span>Update Ω<i>S,e</i><i> </i>using the Eq. (14) or ADAM algo- rithm (learning rate <i>α</i>);</p><p class="s7" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">10: <span class="h2">end for</span></p><p class="s7" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">11: <span class="h2">end for</span></p><p style="padding-left: 32pt;text-indent: -25pt;text-align: left;"><span class="s7">12: </span>Update Ω using ADAM algorithm ( leraning rate <i>γ</i>) to minimize <i>Loss</i><i>total</i>(Ω);</p><p class="s7" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">13: <span class="h2">end for</span></p><p class="s6" style="padding-left: 7pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><span class="p">on performance in Section VII-C and set </span>G<span class="s12">tr</span> <span class="p">as 1.</span></p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">e<span class="s20">=1</span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{ }</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 7pt;text-indent: 9pt;text-align: justify;"><b>Cross-task update</b>: Cross-task update is the process of optimizing global network parameters based on the sum of the loss functions of all tasks in one batch. After intra-task update, the loss function for all tasks in the batch can be estimated based on the related tasks and their query sets <span class="s17">D</span><i>Qu</i>(<i>e</i>) <i>E</i><span class="s104">batch </span>. These loss functions can be added together to form the loss function used to optimize the global network parameters, i.e.</p><p class="s19" style="padding-top: 6pt;text-indent: 0pt;line-height: 2pt;text-align: center;">E</p><p class="s7" style="padding-top: 4pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">14: <span class="p">Initialize NMSE</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;line-height: 7pt;text-align: left;">total</p><p class="s26" style="padding-top: 3pt;padding-left: 1pt;text-indent: 0pt;line-height: 13pt;text-align: left;">←− <span class="p">0;</span></p><p class="s6" style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 9pt;text-align: left;">Loss<span class="s12">total</span><span class="p">(Ω) =</span></p><p class="s100" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"> <span class="s64">batch</span></p><p style="padding-top: 7pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><i>loss</i><span class="s16">D</span><span class="s116">Qu</span><span class="s83">(</span><span class="s70">e</span><span class="s83">) </span>(<b>Ω</b><i>S,e</i>) <i>. </i>(15)</p><p class="s6" style="padding-left: 7pt;text-indent: 0pt;text-align: left;"><span class="s7">15: </span><b>for </b>e <span class="p">= 1</span>, ..., E<span class="s12">T</span> <b>do</b></p><p class="s7" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">16: <span class="s75">Meta-adaption stage</span></p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">←−</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 7pt;text-indent: 0pt;text-align: left;"><span class="s7">17: </span>Initialize the network parameters Ω<i>e</i><i> </i>Ω;</p><p class="s6" style="padding-left: 7pt;text-indent: 0pt;text-align: left;"><span class="s7">18: </span><b>for </b>j <span class="p">= 1</span>, ..., G<span class="s12">Ad</span> <b>do</b></p><p class="s19" style="padding-top: 5pt;padding-left: 15pt;text-indent: 0pt;text-align: center;">e<span class="s20">=1</span></p><p style="padding-top: 4pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">This loss function can be minimized by optimizing Ω by gradient descent or ADAM algorithm (learning rate <i>γ</i>).</p><p style="padding-left: 17pt;text-indent: 0pt;line-height: 6pt;text-align: left;">After the cross-task update is over, assign the updated Ω</p><p style="padding-left: 7pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s7">19: </span>Randomly select <i>N</i><i>batch</i><i> </i>samples from <span class="s17">D</span><i>Ad</i>(<i>e</i>) to</p><p style="padding-left: 42pt;text-indent: 0pt;line-height: 7pt;text-align: left;">construct <span class="s17">D</span><i>AdB</i>;</p><p style="padding-top: 6pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">to Ω</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="text-indent: 0pt;line-height: 8pt;text-align: left;">S,e</p><p style="padding-top: 6pt;text-indent: 0pt;text-align: left;">, and then repeat the intra-task update and cross-task</p><p style="padding-top: 5pt;padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;"><span class="s7">20: </span>Update Ω<i>e</i><i> </i>using the ADAM algorithm ( learning rate</p><p style="padding-left: 7pt;text-indent: 0pt;line-height: 11pt;text-align: left;">update until <i>Loss</i><i>total</i>(Ω) does not converge. At this time, the</p><p class="s6" style="padding-top: 5pt;padding-left: 42pt;text-indent: 0pt;text-align: left;">γ<span class="p">) to minimize </span>Loss<span class="s16">D</span></p><p class="s7" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">21: <span class="h2">end for</span></p><p class="s7" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">22: <span class="s75">Meta-testing stage</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s64" style="text-indent: 0pt;text-align: left;">AdB</p><p style="padding-top: 5pt;text-indent: 0pt;text-align: left;">(<b>Ω</b><span class="s110">e</span>);</p><p style="padding-left: 7pt;text-indent: 0pt;text-align: justify;">parameter initialization of network learning is obtained, so that only a small number of samples can be adapted to the new environment.</p></li><li><p class="s6" style="padding-left: 30pt;text-indent: -13pt;line-height: 5pt;text-align: left;">Meta-Adaption Stage: <span class="p">For the </span>e<span class="s27">th</span> <span class="p">target environment,</span></p><p style="padding-left: 7pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s7">23:       </span><span class="s111">Predict the downlink features </span><b>x</b>ˆ<i>B</i><i>  </i>using Eq. (10);</p><p style="padding-left: 7pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="s7">24: </span>Calculate NMSE(<i>e</i>) using Eq. (4);</p><p style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="s7">25: </span>NMSE<i>total</i><i> </i><span class="s26">←− </span>NMSE<i>total</i><i> </i>+ NMSE(<i>e</i>);</p><p style="padding-top: 6pt;padding-left: 7pt;text-indent: 0pt;line-height: 12pt;text-align: justify;">first use the parameters Ω of the meta-training model to initialize the network model parameters Ω<i>e</i><i> </i>in the target environment. Then use the adaptation set in the</p><p class="s7" style="padding-left: 7pt;text-indent: 0pt;line-height: 5pt;text-align: left;">26: <span class="h2">end for</span></p><p class="s106" style="padding-left: 5pt;text-indent: 0pt;line-height: 13pt;text-align: left;"><span class="s112"> 27: </span>NMSE <span class="s113">←− </span>NMSE<i>total</i><i>/E</i><i>T</i><i> </i>;                                              </p><p style="padding-left: 86pt;text-indent: 0pt;line-height: 0pt;text-align: right;"><span class="s17">D</span><i>Ad</i>(<i>e</i>)</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">target environment to optimize the parameter Ω<i>e</i><i> </i>to minimize</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><i>Loss</i><span class="s16">D</span><span class="s109">Ad </span>(<b>Ω</b>).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="277" height="211" alt="image" src="DTL_KG_files/Image_020.png"/></span></p><p class="s121" style="padding-left: 3pt;text-indent: 0pt;line-height: 9pt;text-align: left;">E1</p><p class="s122" style="padding-top: 4pt;text-indent: 0pt;text-align: left;">Bob</p><p style="text-indent: 0pt;text-align: left;"/><p class="s121" style="text-indent: 0pt;line-height: 9pt;text-align: right;">E2</p><p class="s122" style="padding-top: 2pt;text-indent: 0pt;text-align: right;">Bob</p><p style="text-indent: 0pt;text-align: left;"/><p class="s121" style="text-indent: 0pt;line-height: 9pt;text-align: left;">E3</p><p class="s122" style="padding-top: 2pt;padding-left: 8pt;text-indent: 0pt;text-align: left;">Bob</p><p style="text-indent: 0pt;text-align: left;"/><p class="s122" style="padding-bottom: 2pt;padding-left: 80pt;text-indent: 0pt;text-align: left;">Alice</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="314" height="196" alt="image" src="DTL_KG_files/Image_021.png"/></span></p><p class="s123" style="text-indent: 0pt;line-height: 8pt;text-align: left;">E1</p><p class="s124" style="padding-top: 5pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">Bob</p><p style="text-indent: 0pt;text-align: left;"/><p class="s123" style="text-indent: 0pt;line-height: 8pt;text-align: left;">Alice</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 8pt;text-align: left;"><span class="s123">E3</span><span class="s125" style=" background-color: #612621;"> </span><span class="s126" style=" background-color: #612621;">Bob    </span></p><p style="text-indent: 0pt;text-align: left;"/><p class="s123" style="text-indent: 0pt;line-height: 8pt;text-align: left;">E2</p><p style="text-indent: 0pt;text-align: left;"/><p class="s124" style="text-indent: 0pt;line-height: 6pt;text-align: left;">Bob</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 20pt;text-indent: 0pt;text-align: left;">Fig. 6: A overview of the ray-tracing indoor scenario.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 18pt;text-indent: 0pt;text-align: left;">Fig. 7: A overview of the ray-tracing outdoor scenario.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s6" style="padding-top: 9pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Meta-Testing Stage: <span class="p">The network parameter Ω</span><span class="s12">e</span> <span class="p">is fixed, and the network is directly used for feature mapping step in the target environment. We calculate the NMSE in the </span>e<span class="s27">th</span> <span class="p">enviornment using the testing data set </span><span class="s17">D</span><span class="s12">T</span> <span class="s12">e</span><span class="p">(</span>e<span class="p">).</span></p></li></ol></li></ol><p class="s6" style="padding-left: 5pt;text-indent: 9pt;text-align: justify;"><span class="p">After repeating the meta-adaption and meta-testing stages in </span>E<span class="s12">T</span> <span class="p">target environments, we calculate the NMSE of target environments to evaluate the performance of the proposed meta-learning algorithm.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 95pt;text-indent: -23pt;text-align: left;">S<span class="s5">IMULATION </span>R<span class="s5">ESULTS</span></p><ol id="l19"><li><p class="s6" style="padding-top: 5pt;padding-left: 19pt;text-indent: -13pt;text-align: justify;">Dataset Generation and Simulation Setup</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">In the simulation, we consider two different scenarios, i.e., indoor and urban scenarios, which are constructed based on the accurate 3D ray tracing simulator Wireless InSite [28].</p><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">A overview of the ray-tracing indoor scenario is illustrated in Fig. 6. The antenna of the base station is located in a small green box on the ceiling of the indoor corridor. The three maroon rectangles represent the possible positions of the user, and each room represents a scene. In addition, since the base station is in the corridor, and the user may be located in the</p><p style="padding-top: 4pt;padding-left: 21pt;text-indent: 0pt;text-align: left;">TABLE I: Default parameters of proposed algorithms</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:14.786pt" cellspacing="0"><tr style="height:9pt"><td style="width:154pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Parameter</p></td><td style="width:80pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 4pt;padding-right: 4pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Value</p></td></tr><tr style="height:9pt"><td style="width:154pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Number of neurons in hidden layers</p></td><td style="width:80pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 4pt;padding-right: 4pt;text-indent: 0pt;line-height: 8pt;text-align: center;">(512,1024,1024,512)</p></td></tr><tr style="height:9pt"><td style="width:154pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Optimization</p></td><td style="width:80pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 4pt;padding-right: 4pt;text-indent: 0pt;line-height: 8pt;text-align: center;">ADAM [27]</p></td></tr><tr style="height:18pt"><td style="width:154pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Exponential decay rates for ADAM:</p><p class="s129" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 9pt;text-align: center;"><span class="s128">(</span>ρ<span class="s130">1</span>, ρ<span class="s130">2</span><span class="s128">)</span></p></td><td style="width:80pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 4pt;padding-right: 4pt;text-indent: 0pt;line-height: 8pt;text-align: center;">(0.9,0.999)</p></td></tr><tr style="height:18pt"><td style="width:154pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Inner-task and across-task learning rate:</p><p class="s131" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 9pt;text-align: center;">(<i>α, β</i>)</p></td><td style="width:80pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 4pt;padding-right: 4pt;text-indent: 0pt;line-height: 8pt;text-align: center;">(1e-3,1e-3)</p></td></tr><tr style="height:18pt"><td style="width:154pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 8pt;text-align: center;">The number of gradient update for</p><p class="s128" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 9pt;text-align: center;">inner-task training</p></td><td style="width:80pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="text-indent: 0pt;line-height: 8pt;text-align: center;">1</p></td></tr><tr style="height:18pt"><td style="width:154pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 16pt;text-indent: 0pt;line-height: 8pt;text-align: left;">the number of the gradient update in</p><p class="s128" style="padding-left: 17pt;text-indent: 0pt;line-height: 9pt;text-align: left;">fine-tuning and meta-adaption stages</p></td><td style="width:80pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 4pt;padding-right: 4pt;text-indent: 0pt;line-height: 8pt;text-align: center;">300</p></td></tr><tr style="height:9pt"><td style="width:154pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Batch size</p></td><td style="width:80pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 4pt;padding-right: 4pt;text-indent: 0pt;line-height: 8pt;text-align: center;">128</p></td></tr><tr style="height:18pt"><td style="width:154pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 8pt;text-align: center;">The number of source task in</p><p class="s128" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 9pt;text-align: center;">meta-learning</p></td><td style="width:80pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 4pt;padding-right: 4pt;text-indent: 0pt;line-height: 8pt;text-align: center;">400</p></td></tr><tr style="height:9pt"><td style="width:154pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 6pt;padding-right: 6pt;text-indent: 0pt;line-height: 8pt;text-align: center;">The number of samples in each source task</p></td><td style="width:80pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 4pt;padding-right: 4pt;text-indent: 0pt;line-height: 8pt;text-align: center;">100</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 8pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">room, all channels in this scenario are NLoS. In addition, the base station is Alice, multiple users are the possible locations of Bob, and the uplink channel and the downlink channel work on channels with frequencies of 2.4 GHz and 2.5 GHz, respectively. The number of OFDM subcarriers is 64 and the bandwidth is 20 MHz. A overview of the ray-tracing urban scenario is illustrated in Fig. 7. The antenna of the base station is located in a small green box with an outdoor height of 20 meters. The three maroon rectangles represent the possible positions of the user, and each rectangle represents a scene. In addition, the base station is Alice, multiple users are the possible locations of Bob, and the uplink channel and the downlink channel work on channels with frequencies of</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">2.4 GHz and 2.5 GHz, respectively. The number of OFDM subcarriers is 128 and the bandwidth is 20 MHz. We choose the first way of realization in indoor scenario and the second way of realization in outdoor scenario.</p><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">In indoor and urban scenarios, assuming that environment 1 (E1) is the source task scenario, a total of 40,000 locations are collected, while environment 2 (E2) and environment 3 (E3) are target task environments, and 5,000 locations are collected in each environment. Due to the different environments in different rooms or in different surroundings, the environment information learned by the model is different, so the model trained in E1 is not suitable for new environments (E2 and E3). In response to this problem, this paper proposes two algorithms to use the collected data in E1 to obtain some prior knowledge, so that pre-trained model can quickly adapt to new environments (E2 and E3).</p><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">The experiment was carried out on a workstation with an Nvidia GeForce GTX 1660Ti GPU and an Inter(R) Core(TM) I7-9700 CPU. This paper uses Tensorflow 2.1 as the under- lying framework of deep learning to build the network. The network parameters and some parameters in training are shown in table I.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s6" style="padding-left: 19pt;text-indent: -13pt;text-align: justify;">Benchmarks</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">For comparison, we introduce other two benchmarks, namely, the direct algorithm, the joint dataset algorithm. The definitions of all algorithms for comparison are listed below:</p><ol id="l20"><li><p style="padding-top: 2pt;padding-left: 25pt;text-indent: -14pt;text-align: justify;">The direct algorithm: this algorithm directly use the model trained in E1 text the performance in E2 and E3 .</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="265" height="194" alt="image" src="DTL_KG_files/Image_022.png"/></span></p><p class="s132" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">E2 E3</p><p class="s132" style="padding-left: 16pt;text-indent: 0pt;line-height: 9pt;text-align: left;">Average</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="264" height="193" alt="image" src="DTL_KG_files/Image_023.png"/></span></p><p class="s133" style="padding-left: 2pt;text-indent: 0pt;line-height: 7pt;text-align: left;">est point</p><p style="text-indent: 0pt;text-align: left;"/><p class="s133" style="padding-left: 13pt;text-indent: 0pt;line-height: 7pt;text-align: left;">low</p><p style="text-indent: 0pt;text-align: left;"/><p class="s132" style="padding-top: 1pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">E2 E3</p><p class="s132" style="padding-left: 16pt;text-indent: 0pt;line-height: 9pt;text-align: left;">Average</p><p style="text-indent: 0pt;text-align: left;"/><p class="s134" style="padding-top: 3pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">0.04 0.04</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s134" style="padding-left: 1pt;text-indent: 0pt;line-height: 10pt;text-align: left;">NMSE</p><p style="text-indent: 0pt;text-align: left;"/><p class="s135" style="padding-left: 1pt;text-indent: 0pt;line-height: 11pt;text-align: left;">NMSE</p><p style="text-indent: 0pt;text-align: left;"/><p class="s134" style="padding-top: 3pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">0.03 0.03</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s134" style="padding-top: 3pt;padding-left: 18pt;text-indent: 0pt;text-align: left;">0.02 <span class="s136">0.02</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s134" style="padding-top: 4pt;padding-left: 18pt;text-indent: 0pt;line-height: 9pt;text-align: left;">0.01</p><p class="s134" style="padding-left: 25pt;text-indent: 0pt;line-height: 9pt;text-align: center;">1         2                    4                    6                    8</p><p class="s134" style="padding-left: 25pt;text-indent: 0pt;text-align: center;">The number of gradient update for inner-task training G <span class="s137">Tr</span></p><p class="s6" style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="p">Fig. 8: The NMSE performance comparison for different numbers of iterations </span>G<span class="s12">T</span> <span class="s12">r</span><span class="p">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-top: 8pt;padding-left: 25pt;text-indent: -14pt;text-align: justify;">The joint dataset algorithm: this algorithm combine all the data in E1 and prat of data in E2 or E3 to form a joint training dataset, and then use the model trained by the joint training dataset to text the performance in E2 and E3, respectively [22].</p></li><li><p style="padding-left: 25pt;text-indent: -14pt;text-align: justify;">The DTL algorithm: this algorithm use the proposed DTL algorithm in Section V to test the performances.</p></li><li><p style="padding-left: 25pt;text-indent: -14pt;text-align: justify;">The meta-learning algorithm: this algorithm use the pro- posed meta-learning algorithm in Section VI to test the performances.</p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">For fair comparison, some default training parameters adopted in all algorithms are consistent. Furthermore, the datasets used for training and adaptation/fine-tuning in transfer learning and meta-learning algorithms are of the same size. The training dataset used by the joint dataset algorithm is the combination of the training dataset and the adaptation/fine- tuning dataset in the transfer learning and meta-learning algo- rithms.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ol></li><li><p class="s6" style="padding-left: 20pt;text-indent: -14pt;text-align: justify;">The Impact of Hyper-parameters in Meta-learning</p><p class="s6" style="padding-top: 4pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;"><span class="p">The selection of the number of iterations </span>G<span class="s12">T</span> <span class="s12">r</span> <span class="p">in the task and the batch size </span>E<span class="s12">batch</span> <span class="p">in the training phase are very important to the meta-learning-based reciprocal feature construction algorithm. The selection of these two parameters is analyzed below.</span></p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">}</p><p style="text-indent: 0pt;text-align: left;"/><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{</p><p style="text-indent: 0pt;text-align: left;"/><p class="s6" style="padding-left: 5pt;text-indent: 9pt;text-align: justify;"><span class="p">For some tasks, the increase of </span>G<span class="s12">T</span> <span class="s12">r</span> <span class="p">can greatly improve the performance. For example, the reference [22] sets </span>G<span class="s12">T</span> <span class="s12">r</span> <span class="p">to 3, which improves the downlink channel prediction accu- racy in massive MIMO systems. At the same time, as </span>G<span class="s12">T</span> <span class="s12">r</span> <span class="p">increases, more memory and time resources are required for meta-learning training. Therefore, the value of </span>G<span class="s12">T</span> <span class="s12">r</span> <span class="p">should be determined comprehensively by weighing the consumed resources and performance. In this paper, </span>G<span class="s12">T</span> <span class="s12">r</span> <span class="p">is set as 1, 2, 3, 4, 6, 8 for learning, and tests are carried out in the indoor corridor environment respectively. The results are shown in Fig. 8. The results show that with the increase of </span>G<span class="s12">T</span> <span class="s12">r</span><span class="p">, the performance of the meta-learning algorithm does not improve,</span></p><p class="s134" style="padding-top: 3pt;padding-left: 18pt;text-indent: 0pt;line-height: 9pt;text-align: left;">0.01</p><p class="s134" style="padding-left: 36pt;text-indent: 0pt;line-height: 9pt;text-align: left;">14 8 16 32 64 128</p><p class="s135" style="padding-left: 50pt;text-indent: 0pt;text-align: left;">The batch size for meta-training: E <span class="s138">batch</span></p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">Fig. 9: The NMSE performance comparison for different numbers of the batch size <i>E</i><i>batch</i>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s6" style="padding-top: 8pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="p">but basically stabilizes around a certain range. Therefore, in order to guarantee the minimum resource consumption, the </span>G<span class="s12">T</span> <span class="s12">r</span> <span class="p">is set to 1.</span></p><p class="s6" style="padding-left: 5pt;text-indent: 9pt;text-align: justify;"><span class="p">Reasonable selection of the batch size </span>E<span class="s12">batch</span> <span class="p">in the training phase is also very important for the training effect. Since the choice of batch size </span>E<span class="s12">batch</span> <span class="p">has nothing to do with the resource consumption of training, it is only necessary to focus on the training performance under different batch sizes. Fig.</span></p><p class="s6" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="p">9 compares the NMSE performance under different batch sizes </span>E<span class="s12">batch</span><span class="p">. The results show that in the indoor corridor environment, with the increase of </span>E<span class="s12">batch</span><span class="p">, the tested NMSE performance is getting better and better, until </span>E<span class="s12">batch</span> <span class="p">= 32, the performance is optimal. Therefore, in order to achieve optimal performance, the </span>E<span class="s12">batch</span> <span class="p">is set to 32.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s6" style="padding-left: 20pt;text-indent: -14pt;text-align: justify;">Performance of Reciprocal Features</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Fig. 10(a) and Fig. 10(b) compare the NMSE performance of the four algorithms during adaption stage in E2 in the indoor corridor scenario and the outdoor scenario, respectively. Since the direct algorithm has no adaptation phase, it is set as a fixed value for its test results. The results show that the algorithms based on transfer learning and meta-learning are better than the direct and joint dataset algorithms in both indoor corridor scenario and the outdoor scenario. In the indoor corridor scenario, the NMSE of the joint dataset algorithm increases with the increase of the number of iterations <i>G</i><i>Ad</i>,  which is due to the fact that in the joint dataset, the number of data  samples  in E2  is  larger  than  that  in  E1.  Even  in  the indoor corridor environment, the joint dataset algorithm also has the phenomenon of overfitting, but its test performance is still better than the direct algorithm. This result shows that it is necessary to add datasets under new scenarios to the test dataset to improve the performance of the model in new sce- narios. In addition, the meta-learning algorithm is significantly better than the DTL algorithm. In the outdoor scenario, the DTL and meta-learning algorithms can still greatly improve the performance of the model in new environments. Different</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="261" height="205" alt="image" src="DTL_KG_files/Image_024.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s139" style="padding-left: 126pt;text-indent: 0pt;text-align: left;">The direct algorithm</p><p class="s139" style="padding-top: 1pt;padding-left: 126pt;text-indent: 0pt;line-height: 125%;text-align: left;">The joint dataset algorithm The DTL algorithm</p><p class="s139" style="padding-left: 126pt;text-indent: 0pt;text-align: left;">The meta-learning algorithm</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="265" height="203" alt="image" src="DTL_KG_files/Image_025.png"/></span></p><p class="s140" style="padding-left: 16pt;text-indent: 0pt;text-align: left;">The direct algorithm</p><p class="s140" style="padding-left: 16pt;text-indent: 0pt;text-align: left;">The joint dataset algorithm The DTL algorithm</p><p class="s140" style="padding-left: 16pt;text-indent: 0pt;line-height: 7pt;text-align: left;">The meta-learning algorithm</p><p style="text-indent: 0pt;text-align: left;"/><p class="s140" style="padding-top: 4pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">0.08 <span class="s78">0.09</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s140" style="padding-top: 3pt;padding-left: 86pt;text-indent: 0pt;text-align: right;">0.07</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-left: 28pt;text-indent: 0pt;text-align: left;">0.08</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s140" style="padding-top: 3pt;padding-left: 86pt;text-indent: 0pt;text-align: right;">0.06</p><p class="s78" style="padding-top: 4pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">0.07</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s141" style="padding-left: 1pt;text-indent: 0pt;line-height: 8pt;text-align: left;">NMSE</p><p style="text-indent: 0pt;text-align: left;"/><p class="s140" style="padding-left: 86pt;text-indent: 0pt;text-align: right;">0.05</p><p class="s78" style="padding-top: 4pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">0.06</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;padding-left: 91pt;text-indent: 0pt;text-align: center;">0.05</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s142" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">NMSE</p><p style="text-indent: 0pt;text-align: left;"/><p class="s140" style="padding-left: 25pt;text-indent: 0pt;line-height: 7pt;text-align: center;">0.04</p><p class="s78" style="padding-left: 91pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.04</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;padding-left: 91pt;text-indent: 0pt;text-align: center;">0.03</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s140" style="padding-left: 86pt;text-indent: 0pt;text-align: right;">0.03</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s140" style="padding-left: 25pt;text-indent: 0pt;text-align: center;">0                 50               100              150              200              250          300</p><p class="s143" style="padding-top: 1pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">G<span class="s144">Ad</span></p><p class="s7" style="padding-top: 4pt;padding-left: 46pt;text-indent: 0pt;text-align: left;">(a) Indoor corridor scenario.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-left: 86pt;text-indent: 0pt;text-align: right;">0.02</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="text-indent: 0pt;text-align: left;">0 1000 2000 3000 4000</p><p class="s142" style="padding-left: 41pt;text-indent: 0pt;text-align: left;">The size of adaption samples N<span class="s145">Ad</span></p><ol id="l21"><li><p class="s7" style="padding-top: 4pt;padding-left: 58pt;text-indent: -12pt;text-align: left;">Indoor corridor scenario.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="260" height="204" alt="image" src="DTL_KG_files/Image_026.png"/></span></p><p class="s139" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">The direct algorithm</p><p class="s139" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">The joint dataset algorithm</p><p class="s146" style="padding-top: 1pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">              <span class="s139">The DTL algorithm</span></p><p class="s139" style="padding-top: 1pt;padding-left: 20pt;text-indent: 0pt;text-align: left;">The meta-learning algorithm</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="265" height="202" alt="image" src="DTL_KG_files/Image_027.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s140" style="padding-left: 112pt;text-indent: 0pt;text-align: left;">The direct algorithm</p><p class="s140" style="padding-left: 112pt;text-indent: 0pt;text-align: left;">The joint dataset algorithm The DTL algorithm</p><p class="s140" style="padding-left: 112pt;text-indent: 0pt;line-height: 7pt;text-align: left;">The meta-learning algorithm</p><p style="text-indent: 0pt;text-align: left;"/><p class="s147" style="padding-top: 4pt;padding-left: 30pt;text-indent: 0pt;text-align: left;">10<span class="s148">0 </span><span class="s78">10</span><span class="s149">0</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s141" style="padding-left: 1pt;text-indent: 0pt;line-height: 8pt;text-align: left;">NMSE</p><p style="text-indent: 0pt;text-align: left;"/><p class="s142" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">NMSE</p><p style="text-indent: 0pt;text-align: left;"/><p class="s150" style="padding-top: 4pt;padding-left: 28pt;text-indent: 0pt;text-align: left;">10<span class="s151">-1 </span><span class="s152">10</span><span class="s80">-1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s150" style="padding-top: 5pt;padding-left: 86pt;text-indent: 0pt;text-align: right;">10<span class="s151">-2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s140" style="padding-left: 25pt;text-indent: 0pt;text-align: center;">0                 50               100              150              200              250          300</p><p class="s143" style="padding-top: 1pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">G<span class="s144">Ad</span></p></li><li><p class="s7" style="padding-top: 4pt;padding-left: 70pt;text-indent: -12pt;text-align: left;">Outdoor scenario.</p></li></ol><p class="s79" style="padding-top: 4pt;padding-left: 86pt;text-indent: 0pt;text-align: right;">10<span class="s80">-2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;text-indent: 0pt;text-align: left;">0 1000 2000 3000 4000</p><p class="s142" style="padding-left: 42pt;text-indent: 0pt;text-align: left;">The size of adaption samples N<span class="s145">Ad</span></p><p class="s7" style="padding-top: 4pt;padding-left: 58pt;text-indent: 0pt;text-align: left;">(b) Outdoor scenario.</p><p style="padding-top: 9pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">Fig. 10: The NMSE performance during adaption stage.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">from the indoor corridor scenario, the joint dataset algorithm in the outdoor scenario is worse than the direct algorithm, which indicates that the difference between several environments in the outdoor scenario is greater, and adding a small amount of destination environment data to the source environment data will lead to serious overfitting.</p><p class="s6" style="padding-left: 5pt;text-indent: 9pt;text-align: justify;"><span class="p">Fig. 11(a) and Fig. 11(b) compare the influence of the num- ber of adaptation dataset samples </span>N<span class="s12">Ad</span> <span class="p">on the performance of the four algorithms in indoor corridors and outdoor scenarios. Since the direct algorithm does not use the adaptation dataset in the new environments, it is assumed that the performance of the algorithm under different sample numbers is consistent. In the indoor corridor scenario, when the number of samples </span>N<span class="s12">Ad</span> <span class="p">= 1000, since the data in the new environment in the joint dataset only accounts for 1000</span>/<span class="p">41000 of the total data, the resulting overfitting reaction makes the performance of the joint dataset algorithm is even worse than that of the direct algorithm. In the outdoor scenario, even if the number of samples under the target sample </span>N<span class="s12">Ad</span> <span class="p">increases, there will still be an overfitting scene. In addition, in both scenarios,</span></p><p class="s6" style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="p">Fig. 11: The NMSE performance of the four algorithm versus the size of adaption samples </span>N<span class="s12">Ad</span> <span class="p">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">the performance of the algorithm improves with the increase of the number of samples <i>N</i><i>Ad</i>, and the meta-learning and DTL algorithms can achieve fast key genration with a smaller number of samples, and the performance of the meta-learning algorithm is better than that of the DTL algorithm under a small number of samples.</p><p class="s26" style="text-indent: 0pt;line-height: 10pt;text-align: left;">{ }</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">In this paper, testing datasets at 0, 10, 20, 30, 40 dB are generated to analyze the generalization performance under the four algorithms. Figure 12(a) compares the performance of the four algorithms tested under different SNRs in an indoor corridor scenario. The results show that the DTL and meta- learning algorithms can achieve better performance than the direct and joint dataset algorithms. However, at SNRs less than 10 dB, the DTL algorithm achieves worse performance than the direct and joint dataset algorithms for the reciprocal features. At this point, the meta-learning algorithm can still effectively improve the reciprocity of features. Fig. 12(b) compares the performance of the four algorithms tested in outdoor scenario with different SNRs. The DTL and meta-</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="265" height="205" alt="image" src="DTL_KG_files/Image_028.png"/></span></p><p class="s140" style="padding-top: 4pt;padding-left: 114pt;text-indent: 0pt;text-align: left;">The direct algorithm</p><p class="s140" style="padding-left: 114pt;text-indent: 0pt;text-align: left;">The joint dataset algorithm The DTL algorithm</p><p class="s140" style="padding-left: 114pt;text-indent: 0pt;line-height: 7pt;text-align: left;">The meta-learning algorithm</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="265" height="205" alt="image" src="DTL_KG_files/Image_029.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s140" style="padding-left: 115pt;text-indent: 0pt;text-align: left;">The direct algorithm</p><p class="s140" style="padding-left: 115pt;text-indent: 0pt;text-align: left;">The joint dataset algorithm The DTL algorithm</p><p class="s140" style="padding-left: 115pt;text-indent: 0pt;line-height: 7pt;text-align: left;">The meta-learning algorithm</p><p style="text-indent: 0pt;text-align: left;"/><p class="s78" style="padding-top: 4pt;padding-left: 29pt;text-indent: 0pt;text-align: left;">10<span class="s149">0</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-left: 95pt;text-indent: 0pt;text-align: center;">0.5</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;padding-left: 95pt;text-indent: 0pt;text-align: center;">0.4</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s142" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">NMSE</p><p style="text-indent: 0pt;text-align: left;"/><p class="s142" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">KER</p><p style="text-indent: 0pt;text-align: left;"/><p class="s79" style="padding-top: 5pt;padding-left: 26pt;text-indent: 0pt;line-height: 76%;text-align: left;">10<span class="s80">-1</span></p><p class="s78" style="padding-left: 95pt;text-indent: 0pt;text-align: center;">0.3</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;padding-left: 95pt;text-indent: 0pt;text-align: center;">0.2</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s79" style="padding-top: 4pt;padding-left: 86pt;text-indent: 0pt;text-align: right;">10<span class="s80">-2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;padding-bottom: 2pt;text-indent: 0pt;text-align: left;">0 10 20 30 40</p><p style="padding-left: 48pt;text-indent: 0pt;line-height: 7pt;text-align: left;"><span><img width="127" height="10" alt="image" src="DTL_KG_files/Image_030.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-left: 47pt;text-indent: 0pt;text-align: left;">(a) Indoor corridor scenario.</p><p class="s78" style="padding-top: 5pt;padding-left: 86pt;text-indent: 0pt;text-align: right;">0.1</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;padding-bottom: 2pt;text-indent: 0pt;text-align: left;">0 10 20 30 40</p><p style="padding-left: 48pt;text-indent: 0pt;line-height: 7pt;text-align: left;"><span><img width="127" height="10" alt="image" src="DTL_KG_files/Image_031.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="text-indent: 0pt;text-align: left;">(a) The KER performance versus different testing SNRs.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="265" height="205" alt="image" src="DTL_KG_files/Image_032.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s140" style="padding-left: 113pt;text-indent: 0pt;text-align: left;">The direct algorithm</p><p class="s140" style="padding-left: 113pt;text-indent: 0pt;text-align: left;">The joint dataset algorithm The DTL algorithm</p><p class="s140" style="padding-left: 113pt;text-indent: 0pt;line-height: 7pt;text-align: left;">The meta-learning algorithm</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="265" height="205" alt="image" src="DTL_KG_files/Image_033.png"/></span></p><p class="s140" style="padding-left: 16pt;text-indent: 0pt;text-align: left;">The direct algorithm</p><p class="s140" style="padding-left: 16pt;text-indent: 0pt;text-align: left;">The joint dataset algorithm The DTL algorithm</p><p class="s140" style="padding-left: 16pt;text-indent: 0pt;line-height: 7pt;text-align: left;">The meta-learning algorithm</p><p style="text-indent: 0pt;text-align: left;"/><p class="s153" style="padding-top: 4pt;padding-left: 29pt;text-indent: 0pt;text-align: left;">10<span class="s154">0 </span><span class="s78">1.6</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;padding-left: 95pt;text-indent: 0pt;text-align: center;">1.5</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s142" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">NMSE</p><p style="text-indent: 0pt;text-align: left;"/><p class="s142" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">KGR</p><p style="text-indent: 0pt;text-align: left;"/><p class="s79" style="padding-top: 4pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">10<span class="s80">-1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;padding-left: 95pt;text-indent: 0pt;text-align: center;">1.4</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s79" style="padding-top: 4pt;padding-left: 86pt;text-indent: 0pt;text-align: right;">10<span class="s80">-2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;text-indent: 0pt;text-align: left;">0 10 20 30 40</p><p class="s78" style="padding-top: 5pt;padding-left: 86pt;text-indent: 0pt;text-align: right;">1.3</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;text-indent: 0pt;text-align: left;">0 10 20 30 40</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s155" style="padding-left: 90pt;text-indent: 0pt;line-height: 7pt;text-align: left;"><span><img width="127" height="10" alt="image" src="DTL_KG_files/Image_034.png"/></span>	<span><img width="127" height="10" alt="image" src="DTL_KG_files/Image_035.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-top: 1pt;padding-left: 99pt;text-indent: 0pt;text-align: left;">(b) Outdoor scenario.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;text-align: left;">Fig. 12: The NMSE performance versus different SNRs .</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">learning algorithms achieve better performance than other two benchmarks, and the meta-learning algorithm outperforms the DTL algorithm. Furthermore, the performance of the direct and joint dataset algorithms decreases as the SNR increases, suggesting that the two algorithms are largely useless in the outdoor scenario and even degrade the reciprocity of channel features to some extent.</p><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">Overall, the meta-learning and DTL algorithms can achieve better fitting performance and generalization under multiple SNRs, with the meta-learning algorithm achieving better per- formance than the DTL algorithm.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s6" style="padding-left: 19pt;text-indent: -13pt;text-align: justify;">Performance of Initial Keys</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">Based on the above analysis of the performance of the feature reciprocity generated by the algorithms, this section analyzes the performance of the quantized generated keys, which includes KER, KGR, and key randomness in two sce- narios. This section uses the quantization algorithm proposed in Section II-B, where the quantization factor <i>ε </i>= 0<i>.</i>1.</p><p class="s7" style="padding-top: 2pt;padding-left: 40pt;text-indent: 0pt;text-align: left;">(b) The KGR performance versus different testing SNRs.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">Fig. 13: The KER and KGR performance in indoor scenario.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 9pt;text-align: right;">Fig. 13(a) and Fig. 13(b) compare the performance of the keys generated by the four algorithms tested under different SNRs in the indoor corridor scenario. As shown in Fig. 13(a), the KERs of the keys generated by the direct and joint dataset algorithms are as high as 50%. This indicates that the model trained in the source environment is largely invalid in the new environment in the indoor corridor scenario. This is due to the fact that in this scenario, each room represents an environment and there is no similar or common channel environment between each environment. The DTL and meta-learning algorithms can significantly reduce the KER of generating keys in this new environment, where the DTL algorithm generates keys at the SNR of 20 dB with the KER of 30%, which is 38.8% lower compared to the direct algorithm. The KER of the meta-learning algorithm is 23.4% when the SNR is 20 dB, which is 52.9% lower than that of the direct algorithm. As shown in Fig. 13(b), the KERs of the keys generated by the DTL and meta-learning algorithms are also higher than that of the keys generated by the two benchmarks. Fig. 14(a) and Fig. 14(b) compare the performance of the</p><p style="padding-top: 4pt;padding-left: 307pt;text-indent: 0pt;text-align: left;">TABLE II: NIST statistical test pass ratio.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="265" height="205" alt="image" src="DTL_KG_files/Image_036.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s140" style="padding-left: 106pt;text-indent: 0pt;text-align: left;">The direct algorithm</p><p class="s140" style="padding-left: 106pt;text-indent: 0pt;text-align: left;">The joint dataset algorithm</p><p class="s156" style="padding-left: 91pt;text-indent: 0pt;text-align: left;">         <span class="s140">The DTL algorithm</span></p><p class="s140" style="padding-left: 106pt;text-indent: 0pt;text-align: left;">The meta-learning algorithm</p><p style="text-indent: 0pt;text-align: left;"/><table style="border-collapse:collapse" cellspacing="0"><tr style="height:18pt"><td style="width:97pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 12pt;padding-right: 12pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Test</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 17pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Pass ratio</p><p class="s127" style="padding-left: 20pt;text-indent: 0pt;line-height: 9pt;text-align: left;">(indoor)</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 17pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Pass ratio</p><p class="s127" style="padding-left: 18pt;text-indent: 0pt;line-height: 9pt;text-align: left;">(outdoor)</p></td></tr><tr style="height:9pt"><td style="width:97pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 12pt;padding-right: 12pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Approximate Entropy</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.9545</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.8872</p></td></tr><tr style="height:9pt"><td style="width:97pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 12pt;padding-right: 12pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Block Frequency</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.9931</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.9526</p></td></tr><tr style="height:9pt"><td style="width:97pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 12pt;padding-right: 12pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Cumulative Sums</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="text-indent: 0pt;line-height: 8pt;text-align: center;">1</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="text-indent: 0pt;line-height: 8pt;text-align: center;">1</p></td></tr><tr style="height:18pt"><td style="width:97pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 12pt;padding-right: 12pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Discrete Fourier</p><p class="s128" style="padding-left: 12pt;padding-right: 12pt;text-indent: 0pt;line-height: 9pt;text-align: center;">Transform</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="text-indent: 0pt;line-height: 8pt;text-align: center;">1</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.9986</p></td></tr><tr style="height:9pt"><td style="width:97pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 12pt;padding-right: 12pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Frequency</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.9311</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.6908</p></td></tr><tr style="height:9pt"><td style="width:97pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 12pt;padding-right: 12pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Ranking</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.9105</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.8496</p></td></tr><tr style="height:9pt"><td style="width:97pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 12pt;padding-right: 12pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Runs</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.9835</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.9234</p></td></tr><tr style="height:9pt"><td style="width:97pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 12pt;padding-right: 12pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Serial</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.9504</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">0.7451</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"/><p class="s78" style="padding-top: 3pt;padding-left: 29pt;text-indent: 0pt;text-align: left;">10<span class="s149">0</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s142" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">KER</p><p style="text-indent: 0pt;text-align: left;"/><p class="s79" style="padding-left: 26pt;text-indent: 0pt;text-align: left;">10<span class="s80">-1</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s79" style="padding-left: 86pt;text-indent: 0pt;text-align: right;">10<span class="s80">-2</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="127" height="9" alt="image" src="DTL_KG_files/Image_037.png"/></span></p><p class="s78" style="padding-top: 4pt;text-indent: 0pt;text-align: left;">0 10</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;padding-left: 26pt;text-indent: 0pt;text-align: left;">20 30</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s6" style="padding-left: 75pt;text-indent: -12pt;text-align: left;">Complexity Analysis</p></li></ol><p class="s78" style="text-indent: 0pt;line-height: 7pt;text-align: left;">40</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 8pt;padding-left: 62pt;text-indent: 9pt;text-align: left;">We analyze the complexity of the four algorithms in terms of the time required for the training and adaptation phases,</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-left: 86pt;text-indent: 0pt;text-align: right;">0.8</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s142" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">KGR</p><p style="text-indent: 0pt;text-align: left;"/><p class="s78" style="padding-left: 86pt;text-indent: 0pt;text-align: right;">0.7</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s78" style="padding-top: 4pt;padding-left: 86pt;text-indent: 0pt;text-align: right;">0.6</p><ol id="l22"><li><p class="s7" style="padding-top: 6pt;padding-left: 11pt;text-indent: -11pt;text-align: left;">The KER performance versus different testing SNRs.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="265" height="205" alt="image" src="DTL_KG_files/Image_038.png"/></span></p><p class="s156" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">         <span class="s140">The direct algorithm</span></p><p class="s140" style="padding-left: 16pt;text-indent: 0pt;text-align: left;">The joint dataset algorithm The DTL algorithm</p><p class="s140" style="padding-left: 16pt;text-indent: 0pt;line-height: 7pt;text-align: left;">The meta-learning algorithm</p><p style="text-indent: 0pt;text-align: left;"/><p class="s78" style="padding-top: 2pt;padding-bottom: 2pt;text-indent: 0pt;text-align: left;">0 10 20 30 40</p><p style="padding-left: 48pt;text-indent: 0pt;line-height: 7pt;text-align: left;"><span><img width="127" height="10" alt="image" src="DTL_KG_files/Image_039.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s7" style="padding-left: 11pt;text-indent: -11pt;text-align: left;">The KGR performance versus different testing SNRs.</p></li></ol><p style="padding-left: 26pt;text-indent: 0pt;text-align: justify;">the average CPU load, and the GPU memory utilization. load, and GPU memory utilization to analyze the complexity of the four algorithms proposed in this chapter. Table III compares the complexity of the four models. Since the training process of meta-learning includes multiple intra-task and cross-task updates, meta-learning consumes significantly more resources than fine-tuning under a single iteration. However, it was found experimentally that the training process of meta-learning requires only 10 iterations before the loss function stops de- creasing. In addition, since meta-learning uses a small amount of data from multiple scenarios for training, the GPU memory utilization consumed is smaller. The DTL algorithm increases the consumption required for the adaptation phase on top of the direct algorithm, however, the improved performance shows that the consumption is worth it. The meta-learning algorithm consumes fewer resources than the DTL algorithm, but achieves better performance.</p><p style="padding-top: 1pt;padding-left: 26pt;text-indent: 9pt;text-align: justify;">In a real-world scenario, it takes less than 3 minutes in total to train and adapt the network. Compared with the training</p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">Fig. 14: The KER and KGR performance in outdoor scenario.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 7pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">keys generated by the four algorithms tested under different SNRs in the outdoor scenario. As shown in Fig. 14(a), the DTL and mete-learning algorithms can significantly reduce the KER of the generated keys in this environment, where the DTL algorithm generates keys with a KER of 13.37% at a SNR of 20 dB dB, which is 73.14% lower compared to the direct algorithm. The KER of the meta-learning algorithm to generate keys at SNR of 20 dB is 11.305%, which is 77.29% lower compared to the direct algorithm. As shown in Fig. 13(b), when the SNR is higher than 20 dB, the keys generated by the DTL and mete-learning algorithms also have a higher KGR than those generated by the direct and joint dataset algorithms.</p><p style="padding-top: 9pt;padding-left: 5pt;text-indent: 9pt;text-align: justify;">This section uses the NIST test to test the randomness of the generated keys . Table II gives the pass rate of the generated keys in several tests that can be tested, i.e., the ratio of the number of key sets that pass the test to the total number of key sets.</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;">consumption of networks used in other domains, the proposed algorithms can achieve fast key generation in FDD systems.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 116pt;text-indent: -27pt;text-align: left;">C<span class="s5">ONCLUSION</span></p></li></ol></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 9pt;text-align: justify;">In this paper, aiming at the problems of incompatibility of tasks and poor performance of pre-trained network caused by environment changes, we propose the DTL and meta learning algorithms to achieve rapid adaptation in new environments. Simulation results show that both algorithms can effectively improve the performance of generated keys in new environ- ments. In the indoor corridor scenario, when the SNR=20 dB, the KERs of the keys generated by the DTL and meta-learning algorithms are reduced by 38.8% and 52.9%, respectively, compared with the method without adaptation in the new environments. In the outdoor scenario, when SNR=20 dB, the KERs of the keys generated by the DTL and meta-learning methods are reduced by 73.14% and 77.29%, respectively, compared with the methods without adaptation in the new environments. In addition, the complexity analysis shows that the meta-learning algorithm consumes less time and lower CPU and GPU resources than the DTL algorithm.</p><p style="padding-top: 4pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">TABLE  III: Complexity analysis of four  algorithms</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:12.907pt" cellspacing="0"><tr style="height:18pt"><td style="width:83pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 7pt;padding-right: 7pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Algorithm</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Training time</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">CPU average</p><p class="s127" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 9pt;text-align: center;">load</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">GPU memory</p><p class="s127" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 9pt;text-align: center;">utilization</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">Adaption time</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">CPU average</p><p class="s127" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 9pt;text-align: center;">load</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">GPU memory</p><p class="s127" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 9pt;text-align: center;">utilization</p></td></tr><tr style="height:9pt"><td style="width:83pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 7pt;padding-right: 7pt;text-indent: 0pt;line-height: 8pt;text-align: center;">The direct algorithm</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">3min 3s</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">15.82%</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">5.1 / 9.9 GB</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="text-indent: 0pt;line-height: 8pt;text-align: center;">-</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="text-indent: 0pt;line-height: 8pt;text-align: center;">-</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="text-indent: 0pt;line-height: 8pt;text-align: center;">-</p></td></tr><tr style="height:18pt"><td style="width:83pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 7pt;padding-right: 7pt;text-indent: 0pt;line-height: 8pt;text-align: center;">The joint training</p><p class="s128" style="padding-left: 7pt;padding-right: 7pt;text-indent: 0pt;line-height: 9pt;text-align: center;">algorithm</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">4min 13s</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">18.22%</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">5.1 / 9.9 GB</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="text-indent: 0pt;line-height: 8pt;text-align: center;">-</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="text-indent: 0pt;line-height: 8pt;text-align: center;">-</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="text-indent: 0pt;line-height: 8pt;text-align: center;">-</p></td></tr><tr style="height:9pt"><td style="width:83pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 7pt;padding-right: 7pt;text-indent: 0pt;line-height: 8pt;text-align: center;">The DTL algorithm</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">3min 3s</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">15.82%</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">5.1 / 9.9 GB</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">37s</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">10.12%</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">5.1 / 9.9 GB</p></td></tr><tr style="height:18pt"><td style="width:83pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 7pt;padding-right: 7pt;text-indent: 0pt;line-height: 8pt;text-align: center;">The meta-learning</p><p class="s128" style="padding-left: 7pt;padding-right: 7pt;text-indent: 0pt;line-height: 9pt;text-align: center;">algorithm</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">1min 50s</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">12%</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">1 / 9.9 GB</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s127" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">42s</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">10.2%</p></td><td style="width:70pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"><p class="s128" style="padding-left: 8pt;padding-right: 8pt;text-indent: 0pt;line-height: 8pt;text-align: center;">5.1 / 9.9 GB</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 25pt;text-indent: 0pt;text-align: center;">R<span class="s5">EFERENCES</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l23"><li><p class="s7" style="padding-left: 24pt;text-indent: -14pt;text-align: justify;">Y. Zou, J. Zhu, X. Wang, and L. Hanzo, “A survey on wireless security: Technical challenges, recent advances, and future trends,” <i>Proc. IEEE</i>, vol. 104, no. 9, pp. 1727–1765, Sep. 2016.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -14pt;text-align: justify;">G. Li, C. Sun, J. Zhang, E. Jorswieck, B. Xiao, and A. Hu, “Physical layer key generation in 5G and beyond wireless communications: Challenges and opportunities,” <i>Entropy</i>, vol. 21, no. 5, p. 497, May 2019.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -14pt;text-align: justify;">J. Zhang, T. Q. Duong, A. Marshall, and R. Woods, “Key generation from wireless channels: A review,” <i>IEEE Access</i>, vol. 4, pp. 614–626, Jan. 2016.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -14pt;text-align: justify;">L. Jiao, N. Wang, P. Wang, A. Alipour-Fanid, J. Tang, and K. Zeng, “Physical layer key generation in 5g wireless networks,” <i>IEEE Wireless Communications</i>, vol. 26, no. 5, pp. 48–54, 2019.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -14pt;text-align: justify;">G. Li, A. Hu, C. Sun, and J. Zhang, “Constructing reciprocal channel coefficients for secret key generation in FDD systems,” <i>IEEE Commun. Lett.</i>, vol. 22, no. 12, pp. 2487–2490, Dec. 2018.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -14pt;text-align: justify;">W. Wang, H. Jiang, X. Xia, P. Mu, and Q. Yin, “A wireless secret key generation method based on Chinese remainder theorem in FDD systems,” <i>Sci. China Inf. Sci.</i>, vol. 55, no. 7, pp. 1605–1616, Jul. 2012.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -14pt;text-align: justify;">B. Liu, A. Hu, and G. Li, “Secret key generation scheme based on the channel covariance matrix eigenvalues in FDD systems,” <i>IEEE Commun. Lett.</i>, vol. 23, no. 9, pp. 1493–1496, Sep. 2019.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -14pt;text-align: justify;">S. J. Goldberg, Y. C. Shah, and A. Reznik, “Method and apparatus for performing JRNSO in FDD, TDD and MIMO communications,” U.S. Patent 8 401 196 B2, Mar. 19, 2013.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -14pt;text-align: justify;">X. Wu, Y. Peng, C. Hu, H. Zhao, and L. Shu, “A secret key generation method based on CSI in OFDM-FDD system,” in <i>Proc. IEEE Globecom Workshops. (GC Wkshps)</i>, Atlanta, GA, United states, Dec. 2013, pp. 1297–1302.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">D. Qin and Z. Ding, “Exploiting multi-antenna non-reciprocal channels for shared secret key generation,” <i>IEEE Trans.Inf. Forensics Secur.</i>, vol. 11, no. 12, pp. 2693–2705, Dec. 2016.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">A. M. Allam, “Channel-based secret key establishment for FDD wireless communication systems,” <i>Commun. Appl. Electron</i>, vol. 7, no. 9, pp. 27– 31, Nov. 2017.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">X. Zhang, G. Li, Z. Hou, and A. Hu, “Secret key generation for fdd systems based on complex-valued neural network,” in <i>2021 IEEE 94th Vehicular Technology Conference (VTC2021-Fall)</i>. IEEE, 2021, pp. 1–6.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">Z. Wan, K. Huang, and L. Chen, “Secret key generation scheme based on deep learning in fdd mimo systems,” <i>IEICE Transactions on Information and Systems</i>, vol. 104, no. 7, pp. 1058–1062, 2021.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">Z. Hou and X. Zhang, “Secret key generation scheme based on gener- ative adversarial networks in fdd systems,” in <i>IEEE INFOCOM 2021- IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)</i>. IEEE, 2021, pp. 1–6.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">X. Zhang, G. Li, J. Zhang, A. Hu, Z. Hou, and B. Xiao, “Deep-Learning- Based Physical-Layer Secret Key Generation for FDD Systems,” <i>IEEE Internet of Things J.</i>, vol. 9, no. 8, pp. 6081–6094, 2022.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">D. Vasisht, S. Kumar, H. Rahul, and D. Katabi, “Eliminating Channel Feedback in Next-Generation Cellular Networks,” in <i>Proc. ACM SIG- COMM</i>, Florianopolis, Brazil, Aug. 2016, p. 398–411.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">L. Peng, G. Li, J. Zhang, R. Woods, M. Liu, and A. Hu, “An investiga- tion of using loop-back mechanism for channel reciprocity enhancement in secret key generation,” <i>IEEE Trans Mob Comput</i>, vol. 18, no. 3, pp. 507–519, May 2018.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;line-height: 9pt;text-align: justify;">F. Zhuang, Z. Qi, K. Duan, D. Xi, Y. Zhu, H. Zhu, H. Xiong, and</p><p class="s7" style="padding-left: 24pt;text-indent: 0pt;text-align: justify;">Q. He, “A comprehensive survey on transfer learning,” <i>Proceedings of the IEEE</i>, vol. 109, no. 1, pp. 43–76, 2020.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">S. Thrun and L. Pratt, “Learning to learn: Introduction and overview,” in <i>Learning to learn</i>. Springer, 1998, pp. 3–17.</p></li><li><p class="s7" style="padding-top: 7pt;padding-left: 24pt;text-indent: -18pt;text-align: justify;">C. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning for fast adaptation of deep networks,” in <i>International conference on machine learning</i>. PMLR, 2017, pp. 1126–1135.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">J. Zeng, J. Sun, G. Gui, B. Adebisi, T. Ohtsuki, H. Gacanin, and H. Sari, “Downlink csi feedback algorithm with deep transfer learning for fdd massive mimo systems,” <i>IEEE Transactions on Cognitive Communica- tions and Networking</i>, vol. 7, no. 4, pp. 1253–1265, 2021.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">Y. Yuan, G. Zheng, K.-K. Wong, B. Ottersten, and Z.-Q. Luo, “Transfer learning and meta learning-based fast downlink beamforming adapta- tion,” <i>IEEE Transactions on Wireless Communications</i>, vol. 20, no. 3, pp. 1742–1755, 2020.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">Y. Yang, F. Gao, Z. Zhong, B. Ai, and A. Alkhateeb, “Deep transfer learning-based downlink channel prediction for FDD massive MIMO systems,” <i>IEEE Transactions on Communications</i>, vol. 68, no. 12, pp. 7485–7497, 2020.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">Y. Peng, P. Wang, W. Xiang, and Y. Li, “Secret key generation based on estimated channel state information for tdd-ofdm systems over fading channels,” <i>IEEE Transactions on Wireless Communications</i>, vol. 16, no. 8, pp. 5176–5186, 2017.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">A. Rukhin, J. Soto, J. Nechvatal, M. Smid, and E. Barker, “A statistical test suite for random and pseudorandom number generators for cryp- tographic applications,” Booz-allen and hamilton inc mclean va, Tech. Rep., 2001.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">T. Hospedales, A. Antoniou, P. Micaelli, and A. Storkey, “Meta-learning in neural networks: A survey,” <i>arXiv preprint arXiv:2004.05439</i>, 2020.</p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;line-height: 9pt;text-align: justify;">D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”</p><p class="s8" style="padding-left: 24pt;text-indent: 0pt;line-height: 9pt;text-align: justify;">arXiv:1412.6980<span class="s7">, 2014.</span></p></li><li><p class="s7" style="padding-left: 24pt;text-indent: -18pt;text-align: justify;">“Remcom wireless insite.” [Online]. Available: http://www.remcom. com/wireless-insite</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="96" height="120" alt="image" src="DTL_KG_files/Image_040.jpg"/></span></p><h4 style="padding-top: 6pt;padding-left: 86pt;text-indent: 0pt;text-align: right;">Xinwei Zhang <span class="s7">received the B.Eng degree in com- puter science and technology from Henan University of Technology, Zhengzhou, China, in 2018, and received the M.Eng degree in computer technology from Southeast University, Nanjing, China, in 2022. From April 2021 to September 2021, he was a Re- search Assistant with the Department of Computing, The Hong Kong Polytechnic University. His research interests include physical-layer security, secret key</span></h4><p class="s7" style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">generation, blockchain and AI security.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="96" height="120" alt="image" src="DTL_KG_files/Image_041.jpg"/></span></p><h4 style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">Guyue Li <span class="s7">(Member, IEEE) received the B.S. de- gree in information science and technology and the Ph.D. degree in information security from Southeast University, Nanjing, China, in 2011 and 2017, re- spectively.</span></h4><p class="s7" style="padding-left: 88pt;text-indent: 7pt;text-align: justify;">From June 2014 to August 2014, she was a Visiting Student with the Department of Electri- cal Engineering, Tampere University of Technology, Finland. She is currently an Associate Professor with the School of Cyber Science and Engineering,</p><p class="s7" style="padding-left: 5pt;text-indent: 82pt;text-align: justify;">Southeast University. Her research interests include physical-layer security, secret key generation, radio frequency fingerprint, and link signature.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="96" height="119" alt="image" src="DTL_KG_files/Image_042.jpg"/></span></p><h4 style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">Junqing Zhang <span class="s7">received the B.Eng and M.Eng de- grees in Electrical Engineering from Tianjin Univer- sity, China in 2009 and 2012, respectively, and the Ph.D degree in Electronics and Electrical Engineer- ing from Queen’s University Belfast, UK in 2016. From Feb. 2016 to Jan. 2018, he was a Postdoctoral Research Fellow with Queen’s University Belfast. From Feb. 2018 to May 2020, he was a Tenure Track Fellow (Assistant Professor) with University of Liverpool, UK. Since June 2020, he is a Lecturer (Assistant Professor) with University of Liverpool.</span></h4><p class="s7" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">His research interests include Internet of Things, wireless security, physical layer security, key generation, and radio frequency fingerprint identification.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="96" height="118" alt="image" src="DTL_KG_files/Image_043.jpg"/></span></p><h4 style="padding-left: 88pt;text-indent: 0pt;text-align: justify;">Aiqun Hu <span class="s7">(Senior Member, IEEE) received the B.Sc.(Eng.), M.Eng.Sc., and Ph.D. degrees from Southeast University in 1987, 1990, and 1993, re- spectively.</span></h4><p class="s7" style="padding-left: 88pt;text-indent: 7pt;text-align: justify;">He was invited as a Post-Doctoral Research Fel- low with The University of Hong Kong from 1997 to 1998, and a TCT Fellow with Nanyang Technologi- cal University in 2006. He has published two books and more than 100 technical articles in wireless com- munications field. His research interests include data transmission and secure communication technology.</p></body></html>
